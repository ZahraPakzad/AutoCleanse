{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import io\n",
    "import joblib\n",
    "import argparse\n",
    "\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "from tabulate import tabulate\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "from AutoCleanse.utils import *\n",
    "from AutoCleanse.dataloader import PlainDataset, DataLoader\n",
    "from AutoCleanse.autoencoder import *\n",
    "from AutoCleanse.loss_model import loss_CEMSE\n",
    "from AutoCleanse.preprocessor import Preprocessor\n",
    "from AutoCleanse.anonymize import anonymize\n",
    "from AutoCleanse.bucketfs_client import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Device configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fdcfb35dd30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup directory path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT_DIR = os.getcwd()\n",
    "os.chdir(PROJECT_DIR)\n",
    "DATASET_DIR = os.path.join(PROJECT_DIR,'dataset')\n",
    "EVAL_DIR = os.path.join(PROJECT_DIR,'evaluate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataframe and group features by their type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATASET_DIR,'adult.csv')).drop(columns=['fnlwgt','income'])\n",
    "continous_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_columns = df.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "og_columns = df.columns.to_list()\n",
    "df = df[continous_columns+categorical_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "onehotencoder = OneHotEncoder(sparse_output=False)\n",
    "preprocessor = Preprocessor(scaler,onehotencoder)\n",
    "\n",
    "X_train,X_val,X_test = preprocessor.split(df=df,\n",
    "                                        train_ratio=0.7,\n",
    "                                        val_ratio=0.15,\n",
    "                                        test_ratio=0.15,\n",
    "                                        random_seed=42)\n",
    "X_dirty = replace_with_nan(X_test,0.0,42)\n",
    "\n",
    "X_train = preprocessor.fit_transform(input_df=X_train,\n",
    "                                    continous_columns=continous_columns,\n",
    "                                    categorical_columns=categorical_columns)\n",
    "\n",
    "X_val = preprocessor.transform(input_df=X_val,    \n",
    "                               continous_columns=continous_columns,\n",
    "                               categorical_columns=categorical_columns)                          \n",
    "\n",
    "X_test = preprocessor.transform(input_df=X_test,   \n",
    "                                continous_columns=continous_columns,\n",
    "                                categorical_columns=categorical_columns)  \n",
    "\n",
    "X_dirty = preprocessor.transform(input_df=X_dirty,   \n",
    "                                continous_columns=continous_columns,\n",
    "                                categorical_columns=categorical_columns)\n",
    "categories = preprocessor.encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dirty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) Check save/load function of preprocessor\n",
    "\n",
    "Both functiona take in 2 parameters:\n",
    "\n",
    "    - Suffix of the preprocessor name, in the example below would be **preprocessor_main.pkl**\n",
    "    - Save/load location: can either be \"local\" to save/load in the home folder or \"bucketfs\" to save/load to/from Exasol BucketFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "preprocessor.save(\"main\",\"local\")\n",
    "preprocessor.save(\"main\",\"bucketfs\",url=\"http://172.18.0.2:6583\",bucket=\"default\",user=\"w\",password=\"write\")\n",
    "preprocessor2 = Preprocessor(scaler=MinMaxScaler(),encoder=OneHotEncoder(sparse=False))\n",
    "preprocessor2.load(\"main\",\"local\")\n",
    "preprocessor2.load(\"main\",\"bucketfs\",url=\"http://172.18.0.2:6583\",bucket=\"default\",user=\"w\",password=\"write\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert dataframes into datasets, and create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PlainDataset(X_train)\n",
    "val_dataset = PlainDataset(X_val)\n",
    "test_dataset = PlainDataset(X_test)\n",
    "dirty_dataset = PlainDataset(X_dirty)\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    tensor_data = torch.stack([item[0] for item in batch])\n",
    "    indices = [item[1] for item in batch]\n",
    "    return tensor_data, indices\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True,collate_fn=custom_collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True, collate_fn=custom_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True, collate_fn=custom_collate_fn)\n",
    "dirty_loader = DataLoader(dirty_dataset, batch_size=batch_size, shuffle=False, drop_last=True, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [X_train.shape[1],1024,128]   \n",
    "wlc = (1,1) \n",
    "\n",
    "autoencoder = Autoencoder(layers=layers,dropout_enc=[(0,0.0)],dropout_dec=[(0,0.1)], batch_norm=True, \\\n",
    "                          learning_rate=1e-4,weight_decay=1e-5,l1_strength=1e-5,l2_strength=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                 [-1, 1024]         110,592\n",
      "       BatchNorm1d-2                 [-1, 1024]           2,048\n",
      "              ReLU-3                 [-1, 1024]               0\n",
      "           Dropout-4                 [-1, 1024]               0\n",
      "            Linear-5                  [-1, 128]         131,200\n",
      "       BatchNorm1d-6                  [-1, 128]             256\n",
      "              ReLU-7                  [-1, 128]               0\n",
      "            Linear-8                 [-1, 1024]         132,096\n",
      "              ReLU-9                 [-1, 1024]               0\n",
      "          Dropout-10                 [-1, 1024]               0\n",
      "           Linear-11                  [-1, 107]         109,675\n",
      "             ReLU-12                  [-1, 107]               0\n",
      "           Linear-13                  [-1, 107]          11,556\n",
      "================================================================\n",
      "Total params: 497,423\n",
      "Trainable params: 497,423\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 1.90\n",
      "Estimated Total Size (MB): 1.96\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(autoencoder.to(device),torch.tensor(X_train.values).float().to(device).shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) Model can be loaded from checkpoint after instantiation\n",
    "\n",
    "The function takes in 2 parameters:\n",
    "\n",
    "    - Suffix of the preprocessor name, in the example below would be **autoencoder_main.pkl**\n",
    "    - Save/load location: can either be \"local\" to load in the home folder or \"bucketfs\" to load from Exasol BucketFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weight from default/autoencoder/autoencoder_main.pth\n"
     ]
    }
   ],
   "source": [
    "autoencoder.load(\"bucketfs\",\"main\",url=\"http://172.18.0.2:6583\",bucket=\"default\",user=\"w\",password=\"write\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weight from autoencoder_main.pth\n"
     ]
    }
   ],
   "source": [
    "autoencoder.load(\"local\",\"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.train_model(\n",
    "      patience=10,\n",
    "      num_epochs=1,\n",
    "      batch_size=batch_size,\n",
    "      train_loader=train_loader,\n",
    "      val_loader=val_loader,\n",
    "      continous_columns=continous_columns, \n",
    "      categorical_columns=categorical_columns, \n",
    "      categories=categories,\n",
    "      device=device,\n",
    "      wlc=wlc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) Model can be saved after training\n",
    "\n",
    "The function takes in 2 parameters:\n",
    "\n",
    "    - Suffix of the preprocessor name, in the example below would be **autoencoder_main.pkl**\n",
    "    - Save/load location: can either be \"local\" to load in the home folder or \"bucketfs\" to load from Exasol BucketFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "autoencoder.save(\"bucketfs\",\"main\",url=\"http://172.18.0.2:6583\",bucket=\"default\",user=\"w\",password=\"write\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use trained model to clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clean progress:   0%|          | 0/76 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clean progress: 100%|██████████| 76/76 [00:04<00:00, 15.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MAE: 0.00116814\n",
      "\n",
      "MSE: 0.00012697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_data = autoencoder.clean(dirty_loader=dirty_loader,\n",
    "                                test_loader=test_loader,\n",
    "                                df=X_dirty,\n",
    "                                batch_size=batch_size,\n",
    "                                continous_columns=continous_columns, \n",
    "                                categorical_columns=categorical_columns, \n",
    "                                og_columns=og_columns,\n",
    "                                onehotencoder=preprocessor.encoder, \n",
    "                                scaler=preprocessor.scaler,\n",
    "                                device=device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data\n",
    "print(tabulate(df.loc[[28296,28217,8054,4223,22723],og_columns],headers=og_columns,tablefmt=\"simple\",maxcolwidths=[None, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned data\n",
    "print(tabulate(cleaned_data.loc[[28296,28217,8054,4223,22723]],headers=cleaned_data.columns.to_list(),tablefmt=\"simple\",maxcolwidths=[None, 4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use trained model to anonymize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Anonymize progress: 100%|██████████| 76/76 [00:02<00:00, 31.47it/s]\n"
     ]
    }
   ],
   "source": [
    "anonymized_data = autoencoder.anonymize(df=X_test,\n",
    "                                        data_loader=test_loader,\n",
    "                                        batch_size=batch_size,\n",
    "                                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anonymized data\n",
    "print(tabulate(anonymized_data.round(decimals=4).iloc[:5,:32],headers=anonymized_data.columns.to_list(),tablefmt=\"simple\",maxcolwidths=[None, 6]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
