{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import io\n",
    "import joblib\n",
    "import argparse\n",
    "\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "from tabulate import tabulate\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "from AutoCleanse.utils import *\n",
    "from AutoCleanse.dataloader import PlainDataset, DataLoader\n",
    "from AutoCleanse.autoencoder import *\n",
    "from AutoCleanse.loss_model import loss_CEMSE\n",
    "from AutoCleanse.preprocessor import Preprocessor\n",
    "from AutoCleanse.anonymize import anonymize\n",
    "from AutoCleanse.bucketfs_client import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Device configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fcabef6bed0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup directory path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT_DIR = os.getcwd()\n",
    "os.chdir(PROJECT_DIR)\n",
    "DATASET_DIR = os.path.join(PROJECT_DIR,'dataset')\n",
    "EVAL_DIR = os.path.join(PROJECT_DIR,'evaluate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataframe and group features by their type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATASET_DIR,'adult.csv')).drop(columns=['fnlwgt','income'])\n",
    "continous_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_columns = df.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "og_columns = df.columns.to_list()\n",
    "df = df[continous_columns+categorical_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tung/development/AutoCleanse/AutoCleanse/utils.py:99: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[48, 28, 38, nan, nan, 27, 25, 20, 39, 52, 40, 35, 55, 62, nan, 17, 22, nan, 17, 51, 20, nan, 44, 19, 21, 77, 46, nan, 21, 48, 39, 34, nan, nan, 32, 52, 30, 20, 46, 30, 20, 41, 39, 21, 47, nan, 28, nan, nan, 21, 23, 24, 35, nan, nan, 49, 65, 42, nan, 21, nan, 23, 46, 22, 44, 30, 29, 56, nan, 40, 32, 25, nan, nan, nan, 42, 25, 39, 28, 39, 31, nan, 59, 28, 48, 38, nan, 20, 46, 38, 64, nan, 44, 29, 48, 47, 46, 26, nan, 47, 18, 50, nan, 28, 23, 33, 18, 39, 30, 18, 36, 37, 23, 36, 19, 34, nan, 42, nan, 48, 33, 49, 24, nan, 27, 53, nan, 43, 42, 66, 32, nan, 36, 27, 37, 36, 29, 26, 23, 37, 74, 42, 29, nan, 27, 21, 41, 60, 38, 62, 37, 55, 67, 48, 53, 23, 59, 37, 34, 37, 48, 25, 47, 49, nan, 30, 28, 44, 22, 30, nan, 18, 51, 30, 28, 32, 51, 33, 39, 68, 24, 52, 59, 33, 55, 27, nan, 31, 23, 23, 60, 51, 18, 42, nan, 22, 52, 55, nan, 49, 31, 37, 38, 47, 49, 48, 49, nan, 33, 27, nan, 29, 21, 36, nan, 49, 47, 53, 25, 28, 20, nan, 64, nan, 35, 18, 27, 19, 27, 28, nan, nan, nan, 53, 35, 27, 63, 36, nan, 45, nan, 50, 22, 28, 25, 55, 54, nan, 45, 61, 56, nan, 43, 51, 27, nan, 58, 20, 18, 25, 44, nan, 54, nan, 43, nan, 39, 19, 32, 61, 61, 53, 26, 24, 50, 21, 49, nan, 35, 35, 39, nan, 39, 29, 37, 57, 37, 21, 35, 49, 20, 34, 45, 36, 53, 30, 32, nan, 20, 31, 39, 27, 26, nan, 49, 56, 64, 54, 65, 26, 18, 59, 36, 47, 22, nan, nan, 40, 21, 50, 46, 24, 26, 39, nan, 21, 31, nan, nan, 28, 48, nan, 35, 21, 51, 22, 49, 66, 36, 24, nan, 24, nan, 55, 30, 32, 22, 40, nan, 26, 51, nan, 43, 45, 67, nan, 52, 56, 67, 24, 38, 51, nan, 43, 40, 31, 65, 47, 35, 37, nan, 46, nan, 47, 46, 37, 36, 50, 33, 34, 32, 41, 46, 32, 60, 39, 65, nan, 59, 24, nan, 28, 22, 21, 36, 36, nan, 22, 26, nan, 22, 47, 20, 36, 25, nan, 21, 54, 38, 59, 28, 29, 19, nan, nan, nan, 39, 44, 58, 65, 30, 50, 51, 46, nan, 47, 36, 32, nan, 21, 41, 25, 26, 45, 61, 51, 33, 44, 27, nan, 56, nan, 41, 29, 33, nan, 20, 32, 53, 47, 59, 63, nan, 28, 45, 30, 38, 21, nan, 25, 49, 27, nan, nan, 28, 35, 38, 21, 61, 18, 33, 36, 37, 24, 20, nan, nan, nan, 59, 56, 56, 22, 34, 41, 43, 38, 63, 57, 20, nan, 50, nan, 39, 34, 46, nan, 38, 21, 25, 33, 72, nan, nan, 48, 28, 45, nan, 20, 26, 56, 26, 42, nan, nan, nan, 33, 38, 38, 42, nan, 34, 40, 20, 32, 21, 41, 29, nan, 36, 48, nan, 54, nan, 57, nan, 42, 18, 41, nan, nan, 32, 33, 37, 34, nan, 35, 45, 32, 41, 43, 30, 39, 60, 49, 34, 43, 57, 21, 56, nan, 24, 44, nan, 42, 54, 45, 36, 48, 32, 32, 41, 31, 27, nan, nan, nan, 65, 64, nan, 45, 31, 58, 23, 54, nan, 57, 59, 56, 33, 48, 18, nan, nan, 26, nan, 33, nan, 26, 50, 29, 24, 21, 25, 40, nan, 53, 20, 50, 27, 33, 25, 30, 23, nan, nan, 61, nan, nan, nan, 41, 29, 37, 28, 39, 35, 34, 25, 42, 42, 37, 35, 32, 26, 41, 23, 39, 55, nan, 39, 43, 32, 38, 30, 57, 19, nan, 35, 26, 27, 23, 45, 32, 43, nan, 71, 37, nan, 19, 26, 22, 45, 39, 42, 48, nan, 41, nan, 22, 49, 50, 35, nan, nan, 26, 51, 51, nan, 50, 31, 32, 34, 40, 20, nan, 27, 22, 26, nan, 25, 28, nan, 24, 26, 43, nan, nan, 45, nan, 47, 52, nan, 59, nan, 63, 39, 20, 28, 52, 23, 50, 25, 40, 27, 50, nan, 42, 51, 39, 24, 36, 29, 59, 74, 32, 50, 23, 24, nan, 22, 30, 25, 44, 38, 56, 41, 29, 40, 50, 32, 18, nan, 32, 46, 35, nan, nan, 46, 29, 28, 39, 59, nan, 35, nan, 17, 23, 36, 29, 20, 24, 28, 37, 42, 45, nan, 20, 46, 25, 57, 21, nan, nan, nan, nan, 46, nan, 30, 58, 34, nan, 19, nan, nan, 30, 67, 24, nan, 37, 25, 31, 23, 81, 32, 27, 34, 59, 35, 23, 47, 48, 40, 49, 25, nan, 33, nan, 49, 68, nan, 50, nan, 31, 45, 29, 44, nan, nan, 30, 37, 60, nan, 25, 26, 27, 24, 36, 40, 19, 31, 51, 37, nan, 32, nan, 65, 36, 58, nan, nan, 23, 90, 24, 39, 30, 41, 24, 44, 27, nan, nan, 22, 60, nan, 39, 63, 23, 32, nan, 51, 18, 48, 22, 47, 64, 37, nan, 32, 29, 55, 60, nan, 56, 17, 39, 24, 42, 28, 30, 21, 21, 30, nan, nan, 49, 23, 54, nan, 35, 22, 51, nan, nan, 64, 57, 43, 70, nan, nan, 46, 33, 59, nan, 43, 41, 28, nan, nan, 21, 32, 36, 25, 38, 23, 35, 23, 53, 27, nan, 52, nan, nan, 30, nan, 23, 39, 39, nan, 37, 62, 25, 25, nan, 33, 34, 33, 46, 47, 53, 35, 65, 30, nan, 49, 39, 30, nan, 38, 51, 61, 52, 38, 41, nan, 45, 30, nan, nan, 26, 30, 43, 30, 30, nan, 44, nan, nan, 71, 63, 27, nan, nan, nan, 25, 29, nan, 46, 22, nan, 44, nan, 28, nan, 36, 27, nan, 25, 37, nan, 41, 21, 56, nan, nan, nan, 41, 29, 33, 40, 25, 65, 30, nan, 28, nan, 53, 28, 51, 33, 79, 37, 26, 56, 46, 31, 40, 20, 28, 36, 34, nan, 18, 36, 56, 60, nan, nan, 19, 17, 31, 26, 41, 30, 42, 52, 35, 60, 43, 56, 41, 65, 17, 25, 66, 48, 52, nan, 33, nan, nan, 40, 33, 38, nan, 19, nan, 51, 20, 31, 31, 35, 36, nan, 57, nan, 51, nan, nan, 26, 63, 45, 40, 69, 20, 26, 19, 75, 41, nan, 28, 27, 32, 20, 31, 21, nan, 40, 56, nan, nan, 39, nan, nan, 41, 17, nan, 45, 46, nan, 29, 43, nan, nan, 50, nan, 62, 37, 36, 47, 42, 25, nan, 19, 30, 41, 49, 28, 51, nan, 42, 26, 59, 33, 33, 30, 58, 67, 40, 53, nan, 54, 43, 33, 35, 58, 40, 58, 49, 33, 57, 21, 71, 24, 74, 19, nan, 22, nan, 27, 49, 29, 50, 21, 50, 57, 23, 41, 61, nan, 18, nan, 35, nan, 21, nan, nan, nan, 42, 46, 22, nan, 53, 23, nan, nan, nan, 60, 26, 37, 64, 40, 59, 30, 54, 61, 64, 28, 31, 35, nan, 20, 60, nan, 32, 61, 46, 32, 23, 18, 23, nan, 36, 39, 36, nan, 17, nan, 43, 27, 61, 21, 25, 19, 33, 26, 28, 23, 34, 39, 42, 23, 27, 39, 24, 50, 50, 62, 45, 50, 56, 49, 27, 65, 48, 33, 61, nan, 35, 48, 38, nan, 26, 25, 45, nan, nan, 43, 43, 19, nan, 76, 30, 25, 65, 35, 59, 23, 39, 41, nan, 51, nan, 45, 25, nan, 31, 27, 46, 36, 33, nan, 43, 29, 32, 41, 41, 43, 35, 36, 21, 24, 42, 51, 56, 29, 41, 44, nan, 50, 34, 59, 24, 58, nan, nan, nan, 30, 17, 27, 52, 41, 58, 27, 33, 35, 24, 20, 23, 30, 31, nan, 34, 20, nan, 43, 26, nan, nan, 50, nan, nan, 18, 33, 61, 43, nan, 26, 54, 39, 46, nan, 66, 23, 19, 37, nan, 63, 52, 46, nan, 33, 22, 52, nan, 32, 45, 27, nan, 55, 36, nan, 55, 26, 20, 23, 28, 45, 58, nan, 47, 34, 38, 43, 29, 51, 46, 59, nan, 49, 47, nan, 43, 44, nan, 40, 29, 46, 25, 21, nan, 19, nan, 31, 47, 22, nan, nan, 49, 21, 40, nan, 17, 50, 37, 34, 28, 27, 23, 27, 21, nan, nan, 26, 56, 24, 27, nan, 64, 46, 28, 19, 20, 30, 43, 64, 21, 50, 21, 31, nan, 18, 19, nan, nan, 44, 59, 20, 64, nan, 36, 52, nan, 48, 40, 36, 36, nan, 50, 37, 19, 34, 19, 34, nan, 21, 21, nan, 31, 55, 20, 20, 28, nan, 47, 52, 32, 46, nan, 35, nan, 27, 40, 35, 45, 19, 27, 52, 47, 56, 26, 39, 36, 20, 34, 38, 20, nan, 43, 40, nan, 21, 55, 20, 39, nan, 38, 28, 18, nan, 55, 48, nan, 38, 32, nan, 44, 20, 60, nan, nan, nan, 67, 29, 17, 47, 43, 47, 49, 47, 21, nan, 51, 25, 27, 29, nan, nan, 32, 47, 37, 27, 41, 41, 60, 22, 47, 41, 33, 25, 30, 56, 20, 31, 36, 62, 33, 42, 24, 39, 18, nan, nan, 41, 50, 40, 48, 20, 40, 26, 18, nan, 29, 47, 36, 50, 46, 22, nan, nan, 69, 28, nan, 30, 47, 56, 43, nan, 27, 32, 21, 42, 46, 44, nan, 30, 29, nan, 68, 50, 20, 62, nan, 19, 35, 40, 17, 43, 39, nan, 30, 17, 35, 52, nan, 33, 52, 22, 27, nan, 21, nan, 34, nan, 79, nan, 54, nan, 54, 47, nan, 42, 44, 53, 23, nan, 23, 60, 51, 31, 39, nan, 52, 41, 37, 46, 23, 29, 56, 25, 32, 49, nan, nan, nan, nan, 49, nan, nan, 55, 35, 34, 65, 55, 24, 17, 42, 62, 30, 31, 28, 50, 31, 71, nan, nan, 59, 30, nan, 57, 22, nan, 79, 47, 36, 34, nan, 53, 29, 54, 43, 21, nan, 62, 28, nan, 33, 48, 54, 31, 29, 53, nan, 31, 50, nan, 46, nan, 61, 21, 55, 45, 44, 58, 44, 45, 25, 66, nan, 64, 61, nan, 69, 27, nan, 61, 30, 55, 37, 49, 51, 38, nan, 18, 24, 38, 63, 47, 52, 48, 36, 27, 51, 30, 45, 32, 56, nan, 46, 22, 35, nan, 30, nan, 18, nan, 21, 60, 41, 57, 26, 31, 33, 42, 23, 38, 31, nan, 37, 24, 68, 26, nan, 31, 31, 33, nan, 30, 44, 47, 19, 51, 55, 60, 84, 29, 45, nan, 60, nan, 31, nan, 48, 29, 22, 50, 27, 39, 28, nan, 30, nan, 27, 36, 57, 37, 40, 73, 26, nan, 85, 47, 41, 35, 51, 40, 55, nan, 42, nan, nan, 40, 27, 29, 26, 19, 61, 67, 55, nan, 44, nan, 23, 36, 28, 49, nan, 41, 19, 20, 48, 29, 45, 42, 47, 38, 40, 37, nan, nan, 40, 38, 42, 69, 61, 34, 18, 35, nan, nan, 47, 43, nan, nan, 48, 17, 39, 21, 48, 31, 25, 46, nan, 35, 23, 41, 71, nan, nan, 19, 31, nan, 58, 62, 30, 29, 33, 42, 19, 27, 33, 28, 43, 57, 50, nan, 21, 37, 39, 73, 42, 43, 42, 59, 30, 54, 24, 41, 17, 32, 29, 20, 23, 27, 19, nan, 17, nan, 26, 62, 51, 33, 38, 37, 34, 51, 66, 25, nan, 42, nan, 20, 45, 36, nan, nan, 36, nan, 41, 67, 36, 28, nan, 34, 52, 20, nan, 21, 25, 45, 43, nan, 46, 59, nan, 23, 51, nan, 51, 66, nan, 60, nan, nan, 43, 19, 27, 41, 22, nan, 58, nan, 43, 26, nan, 34, 37, 28, 19, nan, 26, 39, 60, 25, nan, 23, 49, 22, 24, 41, nan, 26, nan, nan, 64, 24, 29, 29, 44, 28, 31, 33, 39, 45, 40, 35, 43, 62, 37, nan, 25, 32, nan, 30, 27, 66, 22, 46, nan, nan, 26, 31, 47, 38, 39, 34, 62, 62, 33, 49, 52, 53, nan, 17, 48, 57, 42, nan, nan, 65, 42, 53, 46, nan, nan, 24, 53, 49, nan, nan, nan, 51, 21, 36, nan, 29, 34, 37, 39, 40, 57, 50, 65, 32, 46, 36, 44, 53, 26, 18, 57, nan, 28, 24, 49, 35, 50, 31, 39, 41, 22, 22, 55, nan, 17, 57, 20, nan, nan, 35, 25, 31, 26, nan, 29, nan, 30, 38, 47, 39, 24, 44, nan, 52, 73, 51, 48, 32, 40, 61, 22, 45, 37, 20, 25, 28, 29, 19, 43, 55, 55, nan, nan, 44, 19, nan, 27, 26, 42, 31, nan, 57, 59, nan, 43, 34, 50, 20, 24, 35, 42, 19, 27, 59, 32, 62, nan, 59, 62, 22, 23, 47, 38, 44, 48, 44, 24, 40, 22, nan, 43, 57, nan, 23, 19, nan, nan, 57, 44, 21, 35, 49, 18, 36, 29, 61, 51, 26, nan, 38, 34, 30, 30, 38, 36, nan, 41, 32, nan, 43, 32, 30, 32, 30, 51, 43, nan, 59, 61, 31, 54, 26, 30, 24, nan, 44, 36, 33, 31, 57, 32, 61, 30, 39, 76, 31, 36, 37, 20, 39, 46, 27, 51, nan, nan, 37, nan, 34, 26, nan, 31, 21, 53, 47, 28, 35, 53, 41, 50, 17, 42, 42, nan, 20, 60, 40, 46, 29, 56, nan, 32, 30, 40, 23, 38, 31, 39, 26, 39, nan, 57, 54, nan, 60, 71, 39, nan, nan, 48, nan, 42, 21, 44, 39, 20, 21, nan, 25, 55, 21, 23, 42, nan, 35, 22, nan, 24, 41, 25, nan, 40, 29, 42, 32, 64, 17, nan, 23, 30, 28, 55, nan, nan, 21, 44, 48, 66, 26, nan, 43, nan, 26, 47, 44, 36, 33, nan, 62, 50, 39, 36, nan, 50, 47, 57, 36, 25, nan, 55, 48, nan, nan, 52, 49, 33, nan, 47, 43, nan, 29, 36, 19, 76, 48, nan, 44, nan, 23, nan, 39, 29, 52, 41, 43, 42, 46, 60, 36, 22, 32, 18, 34, 21, 46, 35, nan, 38, 36, 49, 79, 53, 46, 33, 23, nan, 32, nan, 40, 26, 24, 75, 40, 39, nan, 51, nan, nan, 49, 31, 30, 60, nan, 54, 62, 35, 46, 66, 26, 33, 38, nan, 43, nan, 51, 17, 55, 20, 77, 41, 62, 43, nan, 47, 49, nan, 52, nan, 60, nan, nan, 41, 56, nan, 25, 51, 51, 31, 28, nan, nan, 62, 51, nan, 31, 42, 43, 31, 33, 40, 33, 22, 30, 80, 42, 37, 44, 33, nan, 37, 36, nan, 22, 35, nan, 36, 37, 21, 25, 29, 44, 31, 28, 25, nan, 56, 19, 49, 43, 27, 23, 47, 49, 23, nan, 26, 47, 26, 54, 43, 21, 25, 35, 43, 31, 38, 47, 36, 45, 59, 42, 23, 44, 26, 30, 50, 21, 70, 78, 33, 27, 66, 72, nan, 29, nan, 58, 19, 55, nan, nan, 43, 38, 22, 40, 42, 34, 33, nan, 57, 30, 37, nan, 62, 40, 42, 39, nan, 21, 41, 50, 66, 31, 36, 26, 26, 43, 36, 45, 63, 23, 54, 17, 53, nan, 32, 62, 25, 23, 59, nan, nan, nan, 37, 61, 53, nan, 55, 31, 19, 37, 30, 49, 29, 31, 27, nan, 34, 29, nan, nan, 44, nan, 52, nan, nan, 50, 53, nan, 58, 56, nan, nan, 59, 23, 28, 54, 62, nan, 21, 50, nan, 18, 52, nan, 50, 41, 27, 59, 20, 28, 42, 29, 52, nan, 46, 44, 46, 30, nan, 41, nan, nan, nan, 41, 31, 31, 39, 44, 39, nan, nan, 40, 42, 31, 22, nan, 33, 29, nan, 42, 39, 21, nan, 30, nan, nan, 27, 34, 22, nan, 47, 46, 43, 76, nan, 60, 60, nan, nan, 62, 29, 62, nan, 44, 35, 36, 17, 28, 52, nan, 42, 40, 54, 46, 39, 44, 49, 19, 45, 33, 19, 25, 22, 32, 39, 30, 49, 59, 32, nan, nan, 46, nan, 51, 22, 38, 36, 30, 23, 39, 39, nan, 52, 38, 47, 57, 65, 59, 25, 64, 41, 26, 33, 25, 37, nan, 29, 48, 37, 26, nan, 47, 34, 34, 35, 49, 47, 58, nan, 61, 19, 35, 58, 19, 50, 48, 29, 19, 21, 21, nan, 25, 57, nan, 35, 46, 34, 51, 71, 59, 38, 30, 30, nan, 34, 30, nan, 32, 27, nan, 36, 63, 29, 39, 43, 38, nan, 35, 54, 29, 60, 53, nan, 59, nan, 33, 38, 18, nan, 21, 27, 40, 63, 25, 58, 31, 56, 29, nan, 20, 59, 23, 20, nan, 23, 29, 60, 36, 41, 36, 34, nan, 23, 19, 56, nan, 39, 30, 65, 39, 79, 21, 22, 60, nan, 72, 51, 23, 36, 50, 38, 38, 28, nan, 55, 67, 36, 28, 28, 31, nan, nan, 33, 51, 63, 41, 18, 51, nan, 27, 27, 53, 38, 90, 29, 23, 34, 57, 37, 41, 46, 62, 42, nan, 39, nan, nan, 32, 26, 42, 19, 50, 27, 39, nan, 39, 55, 32, 31, 26, 61, 54, 34, 35, 32, 23, 17, 26, nan, 39, nan, 31, 38, nan, 34, 37, 19, 22, 47, nan, 44, 46, 31, 20, 37, 76, 47, 60, 37, 71, 17, 22, 42, 45, 28, 74, 31, 27, 43, 34, nan, 36, 27, nan, 39, 47, 48, 65, nan, 26, 49, 59, 58, 66, 50, 28, 49, nan, nan, 41, 47, 26, 64, 26, 75, 55, 44, 49, 45, nan, 28, 22, 46, 18, nan, 20, 42, 50, 23, 34, 21, 51, 41, 37, nan, 26, 20, 27, 72, 47, 40, 48, 19, nan, 43, 54, 62, 51, 90, 37, 28, 32, 55, 33, nan, 18, nan, 48, 35, 39, nan, 41, 23, nan, 25, 33, 46, 37, 33, 59, 33, 45, nan, 40, 19, 29, nan, nan, nan, 48, 41, 32, nan, 31, 28, 43, 23, 31, 32, 21, 19, 34, nan, nan, 48, nan, 24, 25, nan, 60, nan, nan, 36, 40, 32, 71, 43, 20, 29, 44, nan, 44, 52, 53, nan, 60, 27, 28, 72, 50, 32, 24, 35, 47, nan, 31, 55, 23, 45, nan, 57, nan, 51, 58, 58, nan, 17, nan, 43, 19, nan, 32, 27, nan, 55, 34, 24, 32, nan, 28, 31, nan, 53, 50, nan, nan, nan, 58, nan, 34, 25, nan, 32, nan, 55, 43, 25, 44, 23, 22, 57, 27, nan, 71, 40, 54, 31, 47, 55, 55, 32, 68, nan, 24, 36, 63, 19, nan, 40, nan, 24, 18, 33, 35, nan, 39, 36, nan, 35, nan, 54, 41, nan, nan, 28, 33, 37, 76, 63, 36, 44, 33, 45, 36, 43, 39, 50, 32, 51, 24, 24, 33, 63, 34, 48, 18, 49, 29, 23, 51, 30, 27, nan, 45, 36, nan, 24, nan, 34, 27, nan, 59, 41, 58, 43, nan, 37, 41, 65, 38, 21, 20, nan, nan, 51, nan, 42, nan, 30, 27, nan, 37, 22, 30, 27, 40, 44, 41, 72, 44, 41, 38, 67, 50, 26, 74, nan, 19, 28, 38, nan, 35, 34, 27, 18, 38, 20, nan, 52, 90, 51, 20, 31, 18, 23, 30, 35, 30, 21, 22, 61, 67, 59, 32, nan, 24, 22, 31, 29, 24, 25, 21, 45, 44, 23, nan, 25, 31, 22, 38, 43, nan, 21, 55, 49, 60, 33, 31, nan, 27, 38, nan, nan, 76, 46, 27, nan, 40, 26, 57, 36, 44, 24, 24, 53, 41, 69, nan, 54, 17, nan, 19, 42, 21, 42, 45, 41, 26, 28, nan, 58, nan, 19, nan, 21, 43, 62, 41, 32, 22, 21, 34, 23, 20, 58, 29, 35, 64, 24, 45, nan, 46, 27, 41, nan, 39, nan, 51, 40, 51, 51, 56, 24, 40, 36, 32, 31, 34, 38, 27, 42, 30, 28, 51, nan, 26, 50, nan, 28, 53, 23, 20, 24, 18, 58, 41, 59, 51, 25, 38, 31, 50, 46, 23, 26, 23, 36, 33, 32, 23, 52, 40, 48, nan, nan, 55, 63, 31, nan, 35, 31, 24, 38, 34, 47, 59, 25, 52, 53, 29, nan, 53, 19, 47, 62, 27, 47, 21, 55, 35, nan, 41, nan, 29, nan, 34, nan, 42, 44, 26, 31, 44, 23, nan, 26, nan, 39, 19, 57, 45, 32, nan, 37, nan, 59, 57, 24, 39, 37, 41, 61, nan, 39, 20, 37, 51, 28, 26, 44, nan, 32, 21, 49, nan, 79, 44, 27, 40, 69, 33, 56, 19, 47, 46, 27, 40, 34, nan, 30, 57, nan, 58, 27, 19, nan, 18, 31, nan, nan, 72, 25, 44, 52, 44, 21, 41, 26, 21, nan, nan, 42, 33, 59, nan, 29, 25, 35, 26, 68, nan, 47, 48, 31, 45, 34, 55, 21, 29, 45, 31, 47, 27, nan, 31, 23, 20, 21, 49, nan, nan, nan, 61, 37, 55, 50, 41, 32, 18, 20, 23, 44, 41, nan, 55, 30, nan, 26, nan, 39, 44, 54, 22, 55, 47, 65, nan, 43, 40, 25, nan, 82, 23, nan, nan, 21, 52, 46, 32, 28, 57, nan, 44, 44, 19, nan, 51, nan, 57, 51, 38, 27, 65, 61, 54, 28, 28, 49, nan, 36, 20, 52, 64, 63, nan, 26, 39, nan, 25, 30, 19, nan, 37, 53, 39, 27, 50, nan, 42, 45, 45, 25, 21, nan, nan, 58, 41, nan, nan, 40, 26, 33, 27, 29, 27, 39, 34, 27, 63, 32, 21, nan, 41, 58, 34, 41, nan, 60, nan, nan, 60, nan, nan, 26, 31, 69, nan, nan, 34, 45, 34, 28, nan, 40, 18, 21, 32, 64, 22, 39, 35, 46, nan, 34, 61, 30, 49, 60, 25, 40, 23, 38, nan, nan, 48, 29, 36, nan, nan, 26, 17, 24, 19, 54, nan, 27, 77, 30, 29, 44, 38, 31, 60, 32, 18, 21, 32, 38, nan, nan, nan, 38, 35, 26, 47, 50, nan, 26, 65, 24, 29, nan, 25, 43, 42, nan, 45, nan, nan, 32, 60, 38, 32, 60, 38, 29, 24, 49, nan, 33, nan, nan, 25, nan, nan, 52, nan, 49, 41, 25, 31, 42, 54, 19, 21, 33, 47, 49, 33, 36, 62, 54, 33, 34, nan, nan, 25, 65, 48, 66, 17, 45, 47, nan, 40, nan, 28, 30, 26, nan, 42, 43, nan, nan, 38, 65, nan, 54, 31, 50, 53, 43, 32, 35, 48, 33, 31, 23, 25, nan, 46, 39, nan, 24, 27, nan, 27, 33, 51, 58, nan, 36, nan, 48, nan, 58, 33, 43, 44, 40, 24, 47, 54, 24, 41, 26, nan, 41, 50, 59, 50, 23, 35, 17, 45, 33, 52, 35, 28, nan, nan, 27, 43, 41, 27, 43, nan, 43, 33, 45, 19, 33, nan, nan, 38, 44, 31, 22, 28, 36, 21, 28, 67, 52, 53, nan, 58, 30, 73, 37, 28, 25, 31, nan, 39, 51, 19, 51, 28, 32, 68, 44, 34, 22, 60, 21, nan, 28, 38, nan, nan, 18, 21, 40, nan, 73, 61, 19, nan, 47, 31, 50, 50, 36, 42, 43, 24, nan, 38, 32, nan, nan, 30, 29, 52, 33, 36, 37, nan, 24, 49, nan, 30, 43, 33, 40, 59, nan, 36, 24, 65, 26, 19, 41, 47, 43, 23, nan, 63, nan, 51, 29, 41, 17, 54, 23, nan, 32, 48, 22, 33, 17, 49, 24, 17, 46, 54, 31, 35, 73, 62, nan, nan, 60, 35, 30, 47, 36, 65, 47, 41, 48, 57, 36, 25, 26, 38, 68, nan, nan, 26, 29, nan, 42, 34, 48, 38, 62, 28, nan, 44, nan, 28, 52, 78, 35, nan, nan, 44, 59, 29, nan, nan, 58, 54, 57, nan, 36, nan, 24, nan, 36, 44, nan, nan, 55, 27, 62, 24, 32, nan, 45, 28, 68, 53, 52, 31, 44, nan, 18, 22, nan, 28, 36, nan, 28, 22, 61, 69, 40, nan, 29, 45, 44, 45, 56, nan, 49, nan, nan, 45, 62, 18, nan, 41, 63, 75, 33, nan, 44, 57, nan, 23, 26, 42, 27, 45, 19, 27, 18, 45, 35, 41, 21, 27, 65, nan, 51, 42, 21, 30, nan, 26, 50, 68, 39, 59, 19, 18, nan, 27, 49, nan, 69, 26, nan, nan, 20, 38, 26, 42, 26, 19, 45, 35, 34, 42, 69, 23, 23, nan, nan, 46, 39, 43, 32, 37, 42, nan, 29, 44, nan, 48, nan, 44, 59, 31, 35, 54, 22, 24, 40, 41, 25, nan, 29, 20, 40, 20, 27, 40, nan, 44, 68, 51, 38, 38, 33, 34, 37, 54, 47, 22, nan, 42, 26, 24, nan, 20, 31, 60, 41, 40, nan, 58, 48, nan, nan, 26, 26, nan, 29, 59, 50, 59, 35, 44, 41, 51, 38, nan, nan, 43, 28, 36, 34, 38, 21, 51, 65, nan, nan, 44, 43, 20, 27, 28, 56, 51, 47, 22, 32, 25, 38, 55, nan, nan, 35, 19, nan, 35, 28, 40, 68, 18, 38, 31, 26, 29, 42, 18, 19, 21, 68, 31, nan, 51, nan, 18, 38, 24, 54, nan, 24, nan, nan, 19, 52, 33, 23, 34, 51, 37, 45, 38, 29, 26, 31, 27, 56, 27, 24, 49, 60, 22, 48, nan, 19, 48, nan, 27, 29, 64, 47, 19, nan, 51, 46, 53, 56, 23, 34, 90, 25, 23, nan, 46, 18, 34, nan, 24, 25, 40, 41, 62, 35, 44, 17, 44, 63, 19, 43, nan, 36, 34, 18, 50, 40, 26, 72, 21, nan, nan, nan, 38, 49, 18, 45, 58, nan, 26, nan, 20, 38, 43, 51, 21, 50, 47, 56, 51, nan, 31, nan, 38, nan, 47, 33, 33, nan, 47, 22, 38, 34, nan, 24, nan, 25, 20, 66, 19, 38, 24, 63, 25, 23, 53, 62, 54, 28, 29, 28, 34, nan, 32, 19, 52, nan, nan, 49, 26, 23, 19, nan, 36, 24, 41, nan, 20, 43, 23, 48, 26, 38, 19, 55, 28, 50, 60, 60, 52, nan, 54, 29, 60, 60, 21, 35, nan, 46, 59, 44, nan, 19, nan, nan, 50, 58, nan, 37, 23, nan, 42, 26, 30, 18, 36, 36, 41, 41, 51, 38, 28, 41, 25, 60, 56, 37, 20, nan, 23, 19, 34, 40, nan, 37, 23, 40, nan, 47, 22, 22, 35, 38, 39, 55, 51, 34, 23, 23, 26, 25, 65, nan, 76, 25, 24, 28, 23, 84, 38, 52, 61, nan, 26, nan, 61, 19, 31, 77, 35, nan, nan, nan, 24, 38, 32, 31, nan, nan, 36, nan, 23, 17, 26, 24, 33, 48, 17, 32, nan, 30, 46, 68, nan, 58, 39, 20, 39, 34, nan, 63, nan, 22, 42, 73, nan, nan, 50, 43, nan, nan, 39, 40, 48, 40, 26, 28, 41, 62, 76, nan, 45, nan, 56, 33, 30, 46, 61, nan, nan, 28, 29, 37, nan, 22, 23, 38, 47, 19, nan, 24, 71, nan, 56, 19, nan, 54, 39, 21, 45, 59, nan, 46, 46, 22, 42, 44, 29, 33, 48, nan, 21, nan, 46, 50, 30, 20, nan, 20, 20, 25, 40, 70, nan, 41, 28, 20, 35, 46, 52, nan, 17, nan, 39, 65, nan, 38, 61, 32, nan, 34, 39, 21, 27, nan, 20, 39, 53, nan, 35, 31, 39, 64, 66, 60, 44, nan, nan, nan, 33, 47, 21, 31, 29, 24, 27, 53, 24, 22, nan, 40, nan, nan, 31, 30, 28, nan, nan, 67, nan, nan, 53, 71, 21, 24, 28, nan, nan, nan, 48, nan, 29, 22, 34, nan, 63, 20, 28, 28, 55, nan, 23, 18, 42, 45, 64, 43, 36, 34, 37, nan, 38, 37, nan, 73, 45, 48, 25, nan, 26, nan, 57, 61, 25, 36, 44, 21, nan, 22, 31, 39, 45, 26, 37, 57, 66, 48, 22, 43, 48, 20, nan, nan, 38, 77, 44, 69, 43, nan, nan, 18, nan, nan, 48, nan, nan, 44, 24, 47, nan, 49, 43, 43, 68, nan, nan, 25, 41, 39, 24, 40, nan, 44, 26, 20, 38, 33, 57, 49, 28, nan, 42, nan, 46, nan, 34, 55, nan, 46, 40, 18, 53, 45, nan, nan, nan, 18, 18, nan, 51, nan, 42, 31, 23, 59, 48, 45, 24, 50, 58, 24, 43, nan, 31, 34, 17, 37, 21, 30, 20, 65, 42, 39, 29, 29, 23, 43, 26, 34, nan, nan, 35, 27, nan, 49, 35, 22, 37, 54, 23, 37, 34, nan, 69, 48, 29, nan, 29, 50, nan, nan, 22, 25, 62, 34, nan, 38, 47, 34, 47, 43, 28, 47, 25, 30, nan, nan, nan, 27, 39, 56, 32, 27, 37, 20, 36, 50, 35, 40, 48, nan, 22, 24, 34, nan, 43, 56, nan, 37, 50, nan, 36, nan, 19, nan, 48, 55, 36, 36, 39, 37, 35, 22, nan, 35, 17, 17, 22, 23, nan, 33, nan, 24, 20, nan, 55, 57, nan, 47, 39, 22, 51, 48, 63, 33, nan, 25, 33, 43, 39, 51, 34, 41, 43, 28, 47, 77, nan, nan, 68, 18, 55, 40, nan, nan, 44, 30, 20, 33, 62, 59, 55, 62, 34, nan, 63, 26, 51, 31, 25, 58, nan, 65, 24, 37, 22, 35, nan, 23, 48, 63, nan, 37, 41, 80, 39, 35, 28, 20, 18, 25, 21, 48, nan, 29, 36, nan, 61, 50, 36, 67, 34, 54, 57, nan, 49, nan, 48, 41, nan, 59, 33, 73, nan, 27, nan, nan, 45, 18, 58, 45, nan, 36, nan, 56, 19, 51, nan, nan, nan, 43, 35, 25, 19, 39, 42, 26]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df[:] = flat_data.reshape(df.shape)\n",
      "/home/tung/development/AutoCleanse/AutoCleanse/utils.py:99: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[5, 9, 5, nan, 11, 15, 9, 8, 10, 13, 10, nan, 10, 9, 5, 6, 13, 13, 6, 9, nan, nan, 10, 9, 10, 5, 10, 13, 9, 9, 10, 5, 13, nan, 9, 9, nan, nan, 9, nan, 9, 7, 11, 6, 9, nan, 9, nan, 14, 10, nan, nan, 9, 13, 13, 10, nan, 13, 4, 9, 7, 13, nan, 9, nan, 10, 9, 9, 9, nan, 11, 10, 10, 9, 9, 14, nan, 9, 12, 13, 13, 9, 6, 9, 9, nan, 9, 10, 2, 14, 10, 8, nan, 9, 9, 9, 9, 10, 9, nan, 7, nan, 9, 6, 10, 9, 7, nan, 10, 8, 6, nan, 10, 9, nan, 12, 13, 13, 10, 9, 10, nan, 13, 9, 13, 10, nan, 10, 14, 9, 10, nan, 9, 8, 12, 12, 15, 9, 9, 10, 13, 9, 12, 10, 3, 10, 13, 10, 10, 10, 15, 9, nan, 12, 5, 10, 9, 14, nan, 9, 9, 13, 12, 14, nan, 13, 10, 10, nan, 9, 6, 3, 9, 10, 9, nan, 9, 14, 10, nan, 13, nan, 10, 15, 13, 12, 9, nan, nan, 9, 9, 9, 6, nan, 14, 9, nan, nan, 13, 5, nan, 13, 10, 13, 4, 13, nan, 10, 7, 13, 9, 4, nan, 14, 13, 9, 9, 10, 10, 10, 10, nan, 10, 9, 9, 10, 13, 10, nan, 13, 9, 9, 9, nan, 13, nan, 14, 9, nan, 13, 10, 13, 10, 13, nan, nan, 9, 7, 13, 9, 11, 9, 10, 9, 9, nan, 9, 10, 8, 14, 9, nan, 10, 10, 9, nan, 13, 10, 9, 10, 9, nan, 12, 10, 9, 9, 9, 10, nan, 6, 10, 10, 3, 10, 6, 13, 9, nan, 13, nan, 7, 11, 9, 10, 9, nan, 10, 13, 9, 11, 12, nan, 9, nan, nan, 9, 9, 14, 7, 10, nan, nan, nan, nan, 7, 13, 9, 13, 11, nan, 9, 14, nan, 9, 12, 9, 10, nan, nan, 10, 9, nan, 9, 10, 9, 9, 9, 10, 11, 14, nan, 9, 9, 12, 9, 11, 10, 10, 14, 8, 13, 10, nan, 9, 9, 13, 6, 9, 9, 7, 10, 11, nan, 10, 10, 9, nan, nan, nan, 7, 16, 9, 13, nan, nan, 10, 9, 9, 12, 9, 9, 10, 9, nan, 10, 6, 6, 9, nan, nan, nan, 13, 6, 9, 15, 11, 13, 10, 9, 14, nan, 9, nan, 13, nan, nan, 10, 6, 9, 9, 9, 10, 10, nan, 10, nan, 10, 9, 14, 11, 13, 12, 13, 10, 10, 9, 10, 10, 13, 8, 9, nan, 10, 10, 9, 9, 6, 5, 10, nan, 8, nan, nan, 10, 11, 10, 9, 10, 5, 13, 10, 14, 9, 9, 10, 10, nan, 10, 10, 9, nan, nan, 9, nan, 9, 16, nan, nan, 4, 9, nan, nan, 10, 10, 10, 9, 16, 6, 10, 13, 7, 6, 10, nan, nan, 10, nan, 10, 9, 10, 9, 9, 9, 8, nan, 10, 9, 10, 9, 13, 4, 9, nan, 10, 13, 9, 11, nan, 15, 10, nan, 15, 16, 10, 13, 9, 9, 14, nan, 10, 6, 11, 6, 13, 9, 9, nan, 9, 13, 13, 9, nan, nan, nan, nan, 13, nan, 10, nan, 10, 6, 9, nan, 11, 11, 13, 10, 9, 10, 12, 10, 9, nan, 14, 9, 10, nan, 3, nan, 14, nan, 9, 10, nan, 9, 10, nan, 10, 11, 13, 13, 14, 5, 5, 10, 16, 10, 9, nan, nan, nan, nan, nan, 10, 9, nan, 7, 13, 16, 13, nan, 13, 10, 10, 13, 9, 13, 9, 10, 9, nan, 10, 9, 9, 10, 14, 10, nan, 9, 9, 11, 9, 9, 13, 10, 9, 9, 9, nan, 9, 9, nan, 9, 7, 9, 11, 13, 13, 9, 13, nan, 11, 13, 11, 13, 11, 10, 13, 14, 9, 14, 9, 9, 15, 9, 10, 13, 10, 11, 10, nan, 9, nan, nan, 9, 14, 9, 9, 13, 6, nan, 9, 9, 10, nan, 16, nan, 9, 11, 9, 9, 10, 13, 8, 13, 11, 4, 15, nan, 9, 8, nan, 9, nan, 9, 13, nan, 13, 9, 12, 10, 10, 10, nan, nan, nan, 14, 13, nan, 4, 7, 9, 12, 10, 10, 10, 13, 13, 9, 9, 13, 9, 9, nan, 8, 10, 9, 9, 10, 10, 9, 15, 15, 10, 14, 10, 13, nan, 9, nan, 9, 13, 13, 11, 9, 14, 10, 14, 13, 9, nan, nan, 4, nan, 9, 9, 9, nan, 13, nan, 9, 13, 9, nan, 4, 10, nan, nan, 10, 9, 13, 9, 9, nan, 10, 10, 16, 9, nan, nan, 13, 13, 4, 14, nan, 10, nan, nan, nan, 9, 7, 13, 12, nan, nan, nan, 14, 9, 9, 9, 9, 2, 10, 9, 9, 9, 9, 11, 13, 9, 10, 13, 9, 10, nan, 13, 14, 10, 7, 9, 9, nan, 9, 9, nan, 15, nan, 13, 10, nan, 13, nan, 10, 9, nan, 12, 9, 10, 9, 10, nan, 9, nan, 13, 10, 9, nan, 7, 9, 9, 9, 10, nan, 9, 9, nan, nan, 9, 10, 12, 9, 3, nan, 15, 9, 10, 10, 9, 9, nan, 9, 10, 11, 10, 13, 13, nan, nan, 14, 14, 16, 10, 6, 13, 9, nan, 9, nan, 10, 10, 13, 1, 13, 10, nan, 10, 5, 14, 12, 9, 9, 9, nan, nan, nan, 9, 9, 8, 12, 9, 13, nan, 10, nan, nan, 9, nan, 10, 11, 11, 9, 13, 12, 10, 10, 9, 9, 10, 1, nan, 9, 9, nan, nan, 9, 10, 3, nan, nan, 11, 12, 13, 9, 13, nan, 12, nan, 14, 9, nan, 11, 11, 10, 9, nan, 9, 11, 16, 3, 10, nan, 11, 14, 6, nan, 10, 13, 13, 9, 13, nan, 9, 13, nan, 13, 9, 5, 10, 12, 10, 9, 14, 9, 9, 11, 9, 10, nan, 15, nan, 9, 14, 13, 9, 10, 10, 10, 5, 9, nan, 5, 13, nan, 9, 10, nan, 9, 9, 13, 9, 9, 9, 9, 10, 9, 9, 11, 9, 9, 9, nan, 13, 11, 9, 3, 9, 9, 10, 11, 9, 6, nan, 2, 9, 12, 13, 10, nan, 9, nan, nan, nan, 9, 10, 10, 9, 10, 9, 14, 9, 7, nan, 10, 11, 14, nan, 11, 5, 9, 14, 13, nan, 9, 7, 11, 9, 10, nan, 14, 15, 10, 14, 10, 9, 4, 10, 9, 9, 10, 13, nan, nan, 10, 9, 9, nan, 10, 9, 16, 11, nan, 10, nan, 10, 14, 13, 4, 13, 9, nan, 9, 9, 9, 7, 9, 14, 9, 11, 9, 10, 9, 10, 11, 14, 9, nan, 9, 10, 13, 9, nan, 9, 13, 9, 13, 12, 9, 9, 9, 9, 16, 10, 15, 10, nan, 9, 13, 10, 13, 10, 9, 10, 13, 11, 9, 11, nan, 10, 9, nan, 6, 10, 9, 10, 10, 9, 4, 7, 10, nan, nan, nan, 9, 12, 5, 9, 9, 9, 8, 7, nan, 13, nan, 9, 15, 10, nan, 13, 10, 9, 9, 10, 10, 10, 8, nan, 9, nan, 16, 10, 11, 13, 10, 9, nan, 10, 9, 9, 3, nan, 13, nan, 6, 5, 9, 9, 8, 7, 10, 14, 13, 13, 10, 11, 7, nan, nan, nan, 13, 10, nan, nan, 10, 11, 9, 10, 10, 10, 13, 10, 13, 9, 9, 13, 15, 16, 7, 15, 5, nan, 9, 9, 6, 10, 13, 14, 9, 13, 13, 9, 9, 9, 9, 6, 8, 13, 10, 7, 9, 14, 12, 13, 9, 9, 13, 9, nan, nan, nan, 11, nan, nan, 10, nan, 13, 10, 13, 13, 9, 12, 9, 16, 10, 9, 9, 10, 9, 9, 9, 9, nan, 10, 13, 13, 9, 10, 10, nan, 9, nan, 9, 10, 5, nan, nan, 13, nan, 9, nan, 8, 13, nan, nan, 13, 10, 2, 13, 9, nan, 9, 9, 10, 4, 14, 13, 14, 10, 9, 10, 9, 7, 13, 4, 13, 10, 10, nan, 9, 13, nan, 13, 12, 10, 9, 13, 9, 14, 6, 13, 13, 9, 13, 2, 10, 16, nan, 9, 5, 7, 9, 5, 10, 10, 9, 13, nan, 2, 13, 12, 2, 13, 14, 14, 9, 13, nan, 9, 13, 10, 10, nan, 11, 9, 9, 9, nan, 13, 10, 9, 10, nan, nan, nan, 13, 14, 13, 9, 10, nan, 13, 6, 12, 9, nan, 9, 13, nan, 13, 9, 10, 9, 13, 10, 10, nan, nan, 2, 13, nan, 9, nan, 10, nan, 4, 10, 16, 10, 10, 10, 5, 10, 10, 10, nan, 9, 10, 10, 6, 13, 10, nan, 10, 13, 10, 9, 7, 14, 7, 10, 9, 9, 10, 9, 9, 10, nan, 12, 7, 9, 9, 14, 4, 11, 10, 13, 10, 9, 10, 9, 9, 11, 14, nan, nan, 10, 7, nan, 9, nan, 10, 13, 10, 11, 10, 9, 11, 3, 10, 9, 10, nan, 10, 13, 9, nan, nan, 10, 13, nan, 3, 10, 10, 12, 12, 7, 10, 4, 10, nan, 13, 10, 7, nan, 13, 9, 9, 10, 9, 9, nan, 9, 13, 10, 9, 10, 6, 11, 10, 10, 13, nan, 9, 10, 5, 10, nan, nan, 10, 7, 9, nan, 9, nan, 9, 9, 10, 10, 10, 9, 9, nan, 12, 9, 11, 13, 9, 13, 9, 6, 14, 14, nan, 10, 10, 13, 10, 10, 9, nan, nan, 10, 13, 12, 9, 4, 9, 9, 14, nan, 16, 2, 10, 13, 6, 13, 9, nan, 9, 10, 4, 12, 9, 9, 13, 7, 9, 12, nan, 10, 8, 6, 8, 9, 9, nan, 13, nan, 6, 9, nan, 10, 14, 9, 13, 13, 13, 9, nan, 4, 11, 9, 10, 10, 13, 10, 13, 9, nan, nan, 10, 11, 9, 10, nan, 9, 10, 13, 9, 10, 10, 12, 7, 14, 10, 9, 9, 13, 9, 15, nan, 9, 3, 13, 7, 9, 9, 9, nan, 13, 10, 9, nan, 13, nan, 9, 10, 13, 10, 9, 11, nan, 10, 9, 9, 6, 13, 9, 6, 7, 11, 9, 11, 10, 10, 9, 13, nan, 12, 10, 12, nan, nan, 15, 13, 10, nan, 10, 10, 6, 9, 11, 13, 9, 10, 13, 13, 9, nan, 3, 10, 9, 13, 7, nan, 9, 9, 10, 12, 12, 13, 13, 9, 10, 13, 9, 4, nan, 9, 11, nan, 10, 9, 13, nan, 2, 11, 9, 9, 9, 15, 10, 10, nan, 12, 9, 9, 11, 9, 10, 10, nan, 13, nan, 10, 14, 10, 16, 9, 16, 13, 9, 13, nan, 10, 7, 10, 9, 13, 6, 10, 10, 10, nan, 11, 11, nan, 9, 9, 10, 9, nan, 13, nan, 13, nan, 13, 13, 13, 9, 13, 9, 16, 9, 9, 9, 9, nan, 10, 9, 9, 10, 9, 9, 9, 13, nan, 9, 10, 10, 10, 14, nan, 10, 10, 10, 9, nan, 13, 13, nan, 6, 10, 13, 4, 6, 13, nan, nan, nan, 9, 13, 14, nan, nan, 10, 5, 9, 9, 9, 13, nan, 4, 9, 10, 9, 13, 13, 9, 9, 13, 9, nan, 16, 6, 11, 4, 9, 9, nan, 13, 13, 10, 13, 4, 15, 15, 10, 9, nan, nan, nan, 4, 10, 13, 10, 16, 10, 13, 13, 4, nan, 9, 9, 6, 10, 10, 10, 9, 10, 10, nan, 14, 14, 16, 9, 3, 6, 3, 9, 10, nan, 9, 9, 8, 4, 10, 10, 9, 13, 10, nan, 15, 13, 13, 9, 9, 9, 13, 9, 12, 13, 10, 9, 9, 11, 9, 13, nan, 10, 10, 9, 14, 10, 9, nan, nan, 13, 10, 10, 9, 13, 9, 10, 11, 10, 9, 9, nan, 9, 12, 12, 12, 9, nan, 13, 9, 10, 10, nan, 10, 14, 10, 6, 10, 10, 9, nan, nan, 9, nan, 9, 9, 9, 3, 10, 12, 13, 9, nan, 13, 9, nan, 10, 7, 9, 14, 14, 10, 10, 12, 13, 12, 13, 9, 4, nan, 9, 4, nan, nan, 6, 10, nan, 12, 9, 12, nan, nan, nan, 11, 13, 13, 9, 13, nan, nan, nan, 10, 10, 13, nan, 7, nan, 10, 13, 10, 9, 10, 11, 9, 9, 9, 14, 9, nan, 9, 13, 6, 6, 10, nan, 9, 10, 12, nan, 10, 10, nan, nan, 9, 11, 12, 11, nan, 10, 10, 10, 9, nan, 13, 13, 9, 16, 9, 10, 9, nan, 13, nan, 10, 10, 10, 6, 9, nan, 6, 13, 10, 7, 13, 10, 10, 9, 9, nan, nan, 13, 13, 10, 9, 7, 9, nan, 9, 13, 13, nan, 16, 10, 10, 9, 10, 9, nan, 13, 7, 14, 13, 5, 7, 10, 9, 9, 5, 10, 10, nan, nan, 10, nan, 14, 10, 10, 13, 9, 10, 13, 10, 10, nan, 9, 9, 13, 9, nan, 10, 10, nan, nan, 10, 9, nan, nan, 10, 10, nan, 13, 10, 15, 9, 9, nan, 10, 10, 9, 9, 9, 5, nan, 9, nan, 14, 10, 9, 13, 9, 9, 13, 10, 9, 13, 10, nan, nan, 9, 10, 9, 3, 3, 10, 9, nan, nan, 15, nan, 1, 16, 10, 9, 10, 9, 12, nan, 13, 9, nan, 9, 15, nan, nan, nan, 13, 14, 13, 13, nan, 10, 6, 9, nan, 9, 13, 9, 9, nan, 6, 13, 13, 11, 11, 13, 16, 9, 9, 9, nan, nan, 7, 10, 13, 9, 10, 9, 10, 13, 11, 9, 9, 6, nan, 9, 9, 9, 4, nan, 9, 10, nan, nan, nan, 10, 10, 9, 12, nan, nan, 14, 10, 15, 9, 10, nan, 10, 10, 10, 9, nan, 10, 9, 7, 13, 13, nan, nan, 13, 13, 13, 10, 10, nan, 12, nan, 9, 6, 12, 13, nan, 14, nan, 6, nan, 10, 13, 14, 13, nan, nan, 8, 9, 9, nan, 15, nan, 9, 9, nan, 4, 9, nan, 13, nan, 14, nan, nan, 13, 4, 10, 13, 9, 9, 4, 6, nan, 9, 10, 14, 10, 9, 14, 10, 10, 10, nan, nan, 9, 10, 4, nan, 13, 14, nan, 13, 13, 10, 9, nan, 9, 13, 10, 10, 10, nan, 9, 9, 13, 10, 8, nan, 9, nan, 12, 9, nan, 10, 9, 10, nan, nan, 9, 10, 9, 9, 5, 9, 5, 7, nan, nan, 9, 9, 10, 4, 13, 14, 16, 9, 9, 13, 4, 10, 15, 9, nan, 9, 5, 10, 10, 4, 9, 13, 9, 10, 13, 10, 9, 4, nan, nan, nan, 9, nan, 7, 12, 13, 9, 10, 10, 9, 13, 9, 9, nan, 13, 9, 9, 10, 13, 10, 10, 11, 15, 7, nan, 14, 12, 9, nan, 9, 9, 10, 10, nan, 9, nan, 9, 13, nan, nan, 9, 11, 13, 14, 9, 10, 9, 9, nan, 10, nan, 10, 10, 9, 9, 9, 11, 13, nan, nan, 10, 9, 9, nan, 15, 12, 10, 9, 9, 11, nan, 15, 11, 4, nan, 9, 9, 9, 10, 10, 9, 10, 6, 10, 10, 9, 9, nan, 15, 10, 9, nan, 10, nan, 12, 13, 3, 10, 9, 9, nan, 10, 4, nan, 15, nan, 14, 9, 10, nan, nan, 9, nan, nan, 10, 14, 13, 9, 13, 9, 9, nan, 14, 10, nan, 14, 7, 9, 13, 9, 11, nan, 13, nan, 3, 10, 11, 13, 10, 14, 9, 10, 13, nan, 13, nan, 10, 11, 10, nan, 10, 9, 9, 13, 9, 11, 16, 9, nan, 9, 7, 10, nan, 13, 10, 13, 9, 9, 10, 9, nan, 7, 13, 4, nan, 10, nan, nan, 10, 10, nan, 11, 9, 14, 9, 9, 9, 11, nan, 9, 7, 10, 11, 9, 13, 9, 13, 12, 14, 9, 10, 13, 13, 10, 10, 14, 13, 6, 12, 4, 5, nan, nan, 10, 11, 9, nan, 10, nan, 10, 14, 9, 9, 10, 9, 9, 10, 9, 9, 11, nan, 14, nan, 9, 13, nan, nan, 7, 9, nan, 13, nan, 16, 4, 10, 13, nan, 9, nan, 10, 10, nan, 9, 9, 5, nan, 13, nan, 3, 7, 14, 13, 10, 9, 13, 9, 10, 9, 9, nan, 9, 13, 9, 9, 13, 7, 3, nan, 13, 9, 10, 10, 6, 13, nan, 11, 11, 9, 6, 9, nan, 14, 10, 10, 13, 10, 9, 9, 13, 10, 9, 9, nan, 10, 9, 13, 9, 10, 4, 9, 10, 13, 10, 9, 9, 10, 6, nan, 13, 9, 9, 10, 7, nan, 9, 12, 13, 9, 9, nan, 7, nan, 11, 9, 13, nan, nan, 7, 14, 14, 9, 7, nan, 7, 13, 9, 10, 8, 9, 10, 11, nan, 10, 9, 13, 9, 7, 9, 9, 9, 9, 9, nan, nan, 3, 10, 9, 15, 13, 11, 13, 10, 13, nan, 9, 9, 14, nan, nan, nan, 11, 7, 12, 10, 9, 5, 11, nan, 11, 9, nan, 9, nan, 9, 9, 14, 13, 15, 11, 13, 9, 15, nan, 9, 9, 13, nan, 6, nan, 10, nan, 3, 10, nan, nan, 10, 9, 9, 10, 9, 11, 4, 10, 10, 10, 13, 10, 4, nan, 9, 10, 13, nan, nan, 10, nan, 10, 9, nan, 3, 4, 6, nan, 10, 11, 10, 7, 13, 13, 14, nan, 9, 11, 13, 13, nan, 9, 10, 13, 12, 9, 14, 9, 9, 9, 10, 12, 3, 9, 16, 8, 9, 9, nan, nan, nan, 11, 6, 10, 9, 14, 9, 13, nan, 9, 13, 14, 13, nan, 9, 10, nan, 5, 9, 11, 13, 7, 7, 10, 10, nan, 13, 14, 9, 2, nan, nan, 10, 9, 9, 11, 10, 9, nan, 13, 10, 13, nan, 10, 10, 9, 5, 10, nan, 11, 10, 9, 13, nan, 13, 11, 9, 9, 13, nan, 9, 9, 9, 9, nan, 9, nan, 10, 11, 9, 10, 10, 9, 15, 8, 10, 7, 9, 9, 9, 9, nan, 5, 14, 13, 8, 13, 12, 4, 10, 9, 13, 13, 15, nan, 13, 9, 9, 13, nan, 13, 10, 5, 7, 10, nan, 12, 10, 9, 12, 9, nan, 10, nan, 10, 10, 10, 10, nan, 15, 4, 9, 10, 13, 13, 13, nan, 11, 4, 12, 9, nan, 9, 16, nan, 9, 13, 10, 13, 14, nan, nan, 9, nan, 13, 3, 9, 9, 9, 10, 6, 7, 13, 9, 10, 13, 10, 7, 10, 9, 10, 9, 9, 9, 10, 7, 7, nan, 9, 9, 13, 13, nan, 9, 13, nan, nan, 9, nan, nan, 10, 12, 10, 10, nan, 13, 14, 13, 9, 9, nan, nan, 14, nan, 16, 9, 10, 13, 13, 9, 10, 10, 10, nan, 9, 9, 10, nan, 13, 9, 14, nan, nan, 9, nan, 13, 13, 13, 13, 10, 9, 9, 9, 7, 9, 11, 10, 13, 13, 13, 5, 6, 4, 9, 13, 11, 9, 14, 11, 13, nan, 9, nan, 5, 9, nan, 9, 10, nan, nan, 13, 13, 9, 6, 9, 10, 5, 11, 13, 12, nan, 10, 8, 13, 10, 9, 9, 7, 9, nan, 11, nan, 11, nan, 13, 10, nan, 13, nan, 9, 10, 11, nan, 9, 9, nan, nan, 6, 14, 13, 9, 9, nan, 9, 11, 14, 10, 12, 14, 5, 15, 9, 13, nan, 13, 9, 9, nan, nan, 9, 9, 13, 9, 9, 10, 9, 14, 10, 9, 10, 11, 9, nan, 10, 10, nan, 10, 9, 9, 10, 9, 13, nan, 9, 13, 9, 10, 9, 9, 13, 6, 11, 12, 7, nan, 13, 15, 13, 10, 10, nan, 12, 11, 10, nan, 13, 10, 9, 12, 9, 10, 11, 10, nan, 7, 10, 4, 9, 10, 13, nan, 13, 13, 9, 9, 4, nan, 10, 11, nan, 9, 10, 13, 13, 13, nan, 9, 14, 10, 6, nan, 13, 7, 9, 14, 7, 13, 9, 12, 10, 9, 10, nan, 12, 10, 13, 13, 9, 9, 6, 9, nan, 13, 10, 9, 9, nan, 6, nan, 9, nan, 13, 9, 9, 10, 9, 9, 13, 9, 8, 10, nan, 9, 13, 9, 13, 7, 9, 10, 10, 9, 9, nan, 9, nan, 10, 15, 9, nan, 6, 9, nan, 10, 12, 10, 10, 13, nan, 9, 14, 9, nan, 9, 4, nan, 11, 16, 10, 16, nan, 9, 13, nan, 11, 9, 7, 13, 9, 10, 13, 10, 5, 13, 9, 13, 14, 13, 10, 9, nan, 6, 9, 10, 10, 9, 9, 13, 9, 10, 4, nan, 9, 9, 10, 11, 13, 16, 9, 9, 13, 4, nan, 9, 13, 13, 13, 5, 4, 9, 13, 11, 11, nan, 15, 9, nan, 9, 5, 9, nan, nan, 9, 9, nan, 9, nan, nan, 10, nan, 9, 9, 16, 9, 14, nan, 13, nan, nan, 13, nan, 10, 9, 10, 9, 8, 9, 7, 9, 3, 9, 14, 13, nan, 10, 14, 9, 9, 13, 13, nan, 13, 10, 10, 6, 9, 9, nan, nan, 10, nan, nan, 9, nan, 4, 13, 7, nan, 12, nan, 10, 10, 9, 8, nan, nan, 11, 10, 13, 10, nan, 10, 10, 9, 13, 13, 10, 11, 10, 10, 9, 9, 13, nan, 15, nan, nan, nan, 9, 9, 9, 3, nan, 13, nan, 9, 13, 14, 12, 9, nan, 14, nan, 13, 9, 13, nan, 10, 9, 10, 11, 13, 9, 9, nan, 10, nan, nan, 11, 9, nan, 9, 13, 14, 9, 10, 9, nan, 9, nan, 10, 9, nan, nan, 9, nan, nan, 10, nan, 10, 13, 13, 12, 10, 13, 9, 11, nan, 13, 13, 14, nan, nan, 9, 9, 9, 9, 9, 10, 9, 14, nan, 13, 11, 16, 10, 9, 13, nan, nan, 10, 9, 11, 11, 10, nan, 14, 6, 11, 10, 10, 12, 3, 9, 14, 16, 9, 10, nan, nan, nan, 5, nan, 10, 10, 10, 10, nan, 10, nan, nan, 9, 9, 11, 13, 7, 10, 7, 9, 9, nan, 10, 13, 13, nan, 9, 13, 10, 13, 9, 9, 13, 4, 14, 9, 10, 10, nan, 9, 9, 6, 3, 10, 10, 13, nan, 13, nan, 10, 13, 13, 9, 9, 7, 10, nan, nan, 9, 7, 10, 9, nan, nan, 6, 13, 10, nan, 9, nan, 10, 9, 9, 9, 13, 9, 14, 14, 3, 5, 10, 9, nan, 12, 9, 11, 13, 9, 14, 9, nan, nan, 10, 10, 14, 9, nan, 16, 9, nan, 10, 9, nan, 13, 12, 9, 9, 13, nan, nan, 13, 9, 10, 14, 12, 6, 13, 13, nan, 9, 9, 13, 13, nan, 12, nan, 10, 14, 9, nan, nan, 14, 9, nan, 8, 9, 9, 14, 9, nan, 9, 6, 9, 14, 13, nan, 10, nan, 6, 9, 13, 9, 9, nan, 5, 13, nan, 9, 13, nan, 11, 13, nan, 14, 9, 9, nan, 9, 9, 13, 8, 2, 9, 10, 9, nan, 9, nan, 13, 12, 11, 15, 12, 10, 13, 8, 10, 10, 13, 10, 16, 9, nan, 13, nan, 14, 9, 10, 10, 11, 10, 13, 10, nan, nan, 10, nan, 13, nan, 9, nan, 10, nan, nan, 9, 14, 8, nan, 5, 10, 9, 9, 9, 9, 13, 9, 4, 14, 14, 13, nan, nan, 9, nan, 14, 11, 16, 10, 13, 9, 9, nan, 15, 13, 14, 9, 13, 9, nan, 10, 11, 6, nan, 10, 13, 13, nan, 9, nan, 11, 10, 9, nan, 10, 9, 10, 10, nan, 13, nan, nan, 10, 9, 11, 16, 10, 9, 7, nan, 10, nan, 9, 10, 9, 14, nan, 9, 13, 13, nan, nan, 9, 16, 11, 13, 9, 9, 13, nan, 10, 9, 13, 9, nan, 13, 11, 14, 9, 9, 10, 9, 9, 9, 13, 10, 8, nan, nan, 9, 10, 14, 13, 10, 9, 13, 13, 9, 13, 10, 4, 9, 11, 6, nan, 10, 14, 13, nan, 8, 11, nan, 9, 3, nan, nan, 10, 10, 13, 11, 9, 9, 10, 10, 13, 14, nan, 9, 10, nan, 9, 9, 9, 12, nan, nan, 13, 10, 13, 5, 9, 10, 10, 9, 11, 9, 9, 13, 16, 3, nan, 9, 9, 10, 10, 14, 13, 6, 12, nan, 12, 9, nan, 10, 9, 9, 3, 9, 10, 13, 10, 10, 9, 9, 9, 13, 9, 12, 9, 5, nan, 9, 14, 13, 9, 7, 10, 9, 9, 10, 9, 10, 13, nan, nan, 11, nan, nan, 9, 10, 14, 10, 9, 12, 10, 9, 9, 10, 10, 4, 4, 13, nan, nan, nan, 9, nan, 9, 13, nan, nan, 13, 10, 4, 9, 12, 9, nan, nan, 10, 9, 10, 9, nan, 4, 10, 2, 9, 10, 11, 9, 9, 10, 9, 9, nan, 10, 10, nan, nan, 9, 10, 9, 9, 13, 9, 13, 10, 11, 13, nan, 10, 14, 9, 13, nan, 11, 6, 9, 9, nan, 10, 9, 6, 7, nan, nan, nan, 16, 9, 12, nan, 9, 13, 12, 13, 7, nan, 13, 9, 12, 10, 10, 13, 5, nan, nan, nan, 9, nan, 13, 13, 9, nan, 13, 10, 10, 11, nan, 9, 4, 9, 7, 13, 14, 9, nan, 8, 10, 10, 13, 13, nan, 10, 9, 10, 10, 13, 9, nan, 9, 6, 12, 9, 9, 9, nan, 10, nan, 10, 12, 9, 9, 9, 13, 13, nan, 11, 13, 9, 13, 10, 10, 9, 9, 10, 5, 10, 5, 12, 11, 9, 10, 10, 14, 10, nan, 10, 13, 6, 10, 5, nan, nan, 6, 9, nan, 10, 10, 12, 9, nan, 7, 14, 7, 7, 9, nan, 13, 10, nan, 15, nan, nan, nan, 10, 11, 10, 10, 13, 9, 9, nan, 9, 15, 13, nan, 7, 9, 9, nan, 14, 13, 10, nan, 10, 7, 10, 13, 10, nan, 9, 9, 13, 10, 10, 9, 13, nan, 12, 9, nan, nan, 10, 7, 10, nan, 10, nan, 9, 9, 9, 8, 9, nan, 11, 15, 11, nan, 9, nan, nan, 9, 11, 6, nan, 14, 10, 4, 7, 16, nan, 9, 13, 13, 10, 13, 13, 15, 9, 12, nan, 10, nan, 9, nan, 9, nan, 9, 9, 9, nan, 13, 7, 13, 9, 14, 9, 13, 6, nan, 9, 6, 9, 10, nan, 13, 10, 9, 13, 3, 5, 9, 13, 3, nan, 13, 14, 10, 10, 10, 14, 9, 9, 9, 10, nan, 10, 10, 9, 9, 9, 9, 9, 9, 7, 13, nan, 10, 9, nan, 9, 3, nan, 10, 10, 3, 9, 9, 13, 10, 13, 13, nan, 10, 10, 9, 9, 13, nan, 13, 10, nan, 10, 9, 9, 9, 13, 9, 13, 10, 9, 9, 13, 13, 13, 10, 10, 10, nan, 6, 12, 9, 13, nan, nan, 14, 11, 11, nan, 13, 10, 9, 13, 9, 10, 13, 9, 9, 14, nan, 9, nan, 13, 9, 13, 13, nan, 9, 12, 10, 4, 13, 11, nan, 9, nan, nan, nan, 12, 9, 10, 10, 12, 6, 7, 12, nan, 9, 14, 12, 16, 9, 13, nan, nan, 10, 5, 9, 9, 13, nan, 9, 10, 9, 10, 10, 13, 2, nan, 14, 11, 9, 11, 14, 9, 10, 7, 12, 9, 14, 10, 10, 9, 10, 10, 11, 10, 9, 13, 4, 9, 10, nan, 6, nan, 13, 11, 13, 5, 9, 13, nan, 12, 10, 9, 14, 10, 9, 10, 10, nan, nan, 10, 9, 13, 11, nan, 9, nan, 9, 6, 9, 12, nan, 13, 9, 13, nan, 10, 7, nan, nan, 11, 10, 2, 9, 14, 10, 10, 7, 9, 10, 4, 9, nan, 9, 13, 13, 13, 13, nan, 9, nan, 15, 13, nan, nan, 15, 11, nan, 10, 13, 9, 9, 9, 9, 13, 9, 9, 9, nan, 13, 9, 6, 5, nan, 10, 13, 9, 8, 6, 9, 12, nan, 9, nan, nan, 15, 11, 4, 13, 12, 2, nan, 10, nan, 9, nan, 13, 13, 11, 6, 13, nan, 9, nan, 16, nan, 10, nan, nan, 13, 10, nan, 11, 14, 14, 7, 9, 13, 10, 9, 7, 14, 9, 9, nan, 14, 13, 7, 9, 14, 13, 14, 10, 14, 9, 14, 4, 9, 9, 10, nan, 13, 10, nan, 9, nan, 14, 13, 10, 9, 13, 9, 9, 16, 13, 9, 8, 9, 10, 10, 9, 6, 7, 13, 7, nan, 13, 13, 9, 6, nan, 9, 11, 3, nan, 9, nan, 13, nan, nan, 7, 9, 9, 13, 10, 9, 12, nan, nan, 11, 9, 10, nan, nan, 13, 8, 9, 3, 10, 9, 9, 9, 10, 14, 4, nan, 11, 9, 9, 9, 10, 10, 6, nan, nan, 9, 6, 12, 4, 10, 9, nan, 13, 9, nan, 14, 9, 9, 13, nan, 10, nan, 9, nan, 10, 14, 3, 10, 9, 7, 9, 6, nan, 6, nan, 10, 9, 8, 6, 10, nan, 13, 9, 9, 14, 9, 9, 12, 10, nan, 9, nan, 9, nan, 12, nan, 4, 12, 9, 10, 7, 6, nan, 13, 9, nan, 6, 10, 12, nan, nan, 13, nan, 10, 9, 10, nan, 9, 6, 9, nan, 9, 10, 10, 9, 10, nan, 9, 13, 12, 9, 9, nan, 10, 6, 9, 9, 14, nan, 9, nan, nan, 10, 5, 9, 9, nan, nan, 10, 6, 9, 9, 9, 14, 9, 14, 9, 9, 13, 9, nan, 9, 9, 10, 9, 9, 13, 11, nan, 9, nan, 9, 13, 9, 9, 9, 10, 9, 9, 10, 9, 9, 13, 13, 10, nan, 14, nan, 9, 13, nan, 9, 10, 10, 6, 3, nan, 9, 10, 9, 9, 10, 7, nan, 10, 10, 13, 9, 13, 14, 9, 12, 14, nan, 10, 10, 10, nan, 7, 12, nan, 10]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df[:] = flat_data.reshape(df.shape)\n",
      "/home/tung/development/AutoCleanse/AutoCleanse/utils.py:99: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0, 0, 0, nan, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, nan, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, nan, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5178, nan, 3325, 0, nan, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 7298, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7298, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, nan, 0, 0, 0, 0, 0, nan, 0, nan, 594, 0, 0, 0, 0, nan, nan, 0, nan, nan, 0, nan, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, nan, nan, nan, 0, 0, 0, 0, 0, nan, 0, 0, 14344, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, nan, 2597, nan, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 99999, 0, 0, 0, 0, 0, 0, 15024, 0, 0, nan, 0, nan, 3325, 0, 0, nan, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15024, 0, 0, 0, 0, 15024, nan, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 2829, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 7298, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, 3103, nan, nan, 0, 0, 5178, 0, nan, 0, 0, 0, 0, 7298, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 7688, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, 15024, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 7298, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3325, nan, nan, 0, 0, 0, 7688, 0, 0, nan, 3325, 0, 9386, 0, 0, 0, 0, 0, 0, 0, 0, nan, 8614, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, 14344, nan, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 7688, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7688, 0, 0, 0, 0, 0, 0, 0, 5178, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4650, 0, 0, 0, 0, 0, 0, 0, nan, nan, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 1639, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 3325, 0, 0, nan, 3325, 0, 0, nan, 0, 0, nan, 0, 7298, 2290, nan, 0, 0, 0, 0, nan, 7298, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, nan, 0, 7298, 5178, 0, 0, 0, 0, nan, nan, 7688, nan, 0, 0, 0, 0, nan, 0, 0, nan, nan, nan, 0, 0, 2407, nan, 14084, nan, nan, nan, 0, 0, 0, 0, 0, nan, 2176, 0, 99999, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, nan, 0, nan, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, nan, 0, 0, 0, 0, 0, 15024, 2354, 0, nan, 0, 0, 0, nan, nan, 0, 0, nan, 0, 0, 0, nan, 4416, nan, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 13550, 991, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 15024, 0, nan, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 99999, nan, 0, nan, 0, 0, nan, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 15024, 0, 0, 0, 0, nan, 0, 0, nan, 99999, 0, 0, nan, 99999, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 15024, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 8614, 0, 0, 0, 0, 0, 0, 0, 594, 0, nan, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, nan, 27828, 0, 0, 0, nan, nan, nan, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 15024, 7298, 15024, 0, 0, 14344, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, nan, 0, 4386, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, 15024, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4064, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 5013, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 4787, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7688, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, nan, 0, 594, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, nan, 7298, 0, 0, 0, 0, nan, nan, 0, 0, nan, 0, nan, 0, 0, 0, nan, 0, 0, 7688, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 2176, 0, nan, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, 4386, 0, nan, 0, 0, 0, nan, 0, 0, 4064, 0, nan, nan, nan, 0, 0, 0, nan, 99999, 0, 0, 0, 0, nan, 0, 7688, 0, 7298, 0, 7688, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 15024, 0, 99999, 0, 0, nan, 0, 0, 0, 0, 3273, 0, 0, nan, nan, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, nan, 0, nan, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 7688, 0, nan, 0, 0, 0, 0, 0, nan, 0, nan, nan, 0, 0, 0, 0, nan, 0, 0, 2050, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 4865, 0, 0, 0, 0, 8614, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, 7688, 0, 0, 7298, nan, 0, nan, 0, 0, 99999, 0, 0, 0, 0, 0, 99999, 0, nan, 0, nan, 4064, 99999, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9562, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, 4650, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 99999, 0, 0, 0, 0, nan, nan, 0, 0, nan, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5178, 0, 0, 0, 0, 0, 3674, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, nan, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 13550, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10605, 0, 34095, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, nan, 0, 0, nan, 0, nan, 0, 0, nan, 0, 0, 0, 0, nan, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15024, 13550, 4064, 0, 0, nan, 15024, 0, 0, 0, nan, 0, nan, 0, nan, 0, 13550, 0, 0, nan, 0, nan, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4416, 0, 0, 0, nan, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, 7688, 0, 0, nan, 0, 3137, nan, 0, nan, 0, nan, 0, nan, 0, 0, nan, 0, 0, nan, 0, 0, 0, nan, 15024, 15024, 0, 0, 0, 0, 0, 0, 5178, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, nan, nan, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, 15024, nan, 0, 0, 0, nan, nan, 0, 0, 0, 3137, 4386, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, nan, nan, nan, 0, nan, 0, 0, nan, 0, 0, 0, 2174, 0, 0, nan, 0, 0, nan, 0, 7298, 0, 0, 0, 4064, 0, 0, 15024, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 10520, 0, nan, 0, 0, 0, 0, 0, 20051, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 3325, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5178, nan, 0, 0, 0, 0, 7298, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, 15831, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, 2463, 0, 10520, 4650, 0, 0, 0, nan, 0, 0, 7688, 0, 0, nan, 4865, 0, 0, 0, nan, 0, 0, 7298, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 2105, 0, nan, 0, 0, 0, 0, 0, nan, 10520, 0, 0, 0, 0, 0, 3137, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 15024, 0, 0, 0, 0, 0, nan, 0, 7688, 0, nan, 0, nan, 0, nan, nan, 0, 0, 0, 0, nan, 2174, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 4386, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, nan, nan, 0, nan, nan, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 3103, 0, nan, 0, 0, 0, 0, 0, nan, 0, nan, 2346, nan, 2597, 0, nan, 0, 0, 0, 0, 15024, nan, 0, 0, 0, nan, 0, 0, 7688, nan, 0, 0, nan, 0, nan, 0, 5178, 0, nan, 4386, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, nan, nan, 0, nan, nan, nan, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, 3464, 0, 0, 0, 0, 0, 4386, 0, 0, 0, 4064, 0, 0, 0, 0, 0, nan, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, 1471, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 8614, nan, 0, nan, 3464, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, nan, 0, 6849, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 99999, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 4101, nan, 0, 0, nan, nan, 0, nan, 0, 0, 0, 0, nan, nan, 0, nan, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 3137, 4064, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, nan, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, 2463, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 15024, 0, 0, nan, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, 5013, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, nan, 0, 0, 10520, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13550, 0, nan, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, nan, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, 114, 0, nan, nan, nan, 0, 0, 3325, 0, 0, nan, nan, nan, 0, nan, 0, 0, 0, 0, 0, nan, nan, 0, 0, nan, 0, 0, 2105, 0, 0, 0, nan, 99999, 0, 0, 0, 10605, nan, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2597, 8614, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 594, 0, 99999, 10520, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 2009, 2964, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, nan, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 3942, nan, 5556, nan, 0, 0, 0, 0, nan, 0, 0, nan, nan, nan, 15024, 0, 0, 0, 0, 0, 15024, 0, nan, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, nan, 0, 2174, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, nan, 2885, 0, 15024, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 99999, 0, 0, 6497, 0, nan, 0, 0, 15024, 0, nan, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, nan, 1055, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, nan, 0, 7298, nan, nan, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, 5013, 4064, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, nan, 0, 0, 0, 14344, 0, nan, 0, 0, 0, 0, nan, 3325, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 7298, 0, 0, 0, 0, 0, 0, 0, 14344, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5455, 14344, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10520, 0, 0, 0, 3942, 0, 0, 0, nan, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3103, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, nan, 0, nan, 0, 0, 0, nan, 0, 0, 0, nan, nan, 0, nan, 0, 15024, 0, 0, 0, 0, nan, 0, 0, 0, 5178, nan, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, nan, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, 7298, 0, 0, nan, 0, nan, nan, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, 7298, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, nan, nan, 0, 0, 0, nan, 0, 0, 594, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 3103, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, nan, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, nan, nan, nan, nan, 0, nan, 0, 0, nan, 0, 0, 0, 1471, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 3103, 0, 0, 7298, 0, 0, nan, 0, nan, 0, 0, 2354, nan, 0, 0, 0, 0, nan, 0, 7298, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, nan, 0, 2202, 0, 3942, 0, 13550, 0, nan, 0, 914, nan, 0, 0, 0, 0, nan, nan, 0, 0, nan, 0, nan, 7688, 99999, 0, nan, 3103, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5178, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, nan, 0, nan, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 7298, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 6767, 0, 0, 0, 0, 0, 0, 0, nan, 0, 99999, 0, 0, 3325, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, nan, 2829, 0, nan, nan, nan, 0, 4508, nan, 0, 0, 0, nan, 15024, 0, 0, 0, 2829, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 7688, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 7298, 0, 0, nan, 0, nan, 1848, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, nan, 0, nan, 0, 0, 0, nan, 0, 0, 3464, 0, nan, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, 3464, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, nan, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 15024, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7688, 0, 0, 0, 4386, 0, 5178, nan, 0, 7688, nan, 0, 0, 0, nan, 0, 0, nan, 0, 3103, 0, nan, nan, 0, 0, 0, 0, 0, 0, 5178, 0, 0, 0, 7688, 0, nan, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, 0, 3325, 7298, 0, 0, nan, 0, 0, 7688, 0, nan, 0, 0, nan, 0, 0, nan, nan, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 1409, 0, 0, 0, nan, 7298, nan, nan, 0, nan, 0, 4386, 0, 0, nan, 0, 0, 0, 0, 0, 0, 4650, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, 15024, 0, 0, 0, 15024, nan, nan, 0, 5013, nan, nan, 0, 0, 0, 0, 0, nan, nan, 0, nan, 0, 0, 0, 2105, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, nan, 0, 8614, 0, nan, nan, 0, 0, 5013, 0, 0, 0, nan, 0, nan, 0, 0, nan, 0, 0, nan, 0, 0, 0, nan, 0, 0, nan, 0, nan, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, nan, nan, 0, nan, 0, nan, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, nan, 8614, 0, nan, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 7298, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 6418, 0, 0, 0, nan, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, nan, 0, 3887, 0, 0, 0, nan, 2885, 11678, 15024, 0, 0, 15020, 0, nan, 2977, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 7298, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 7688, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 15024, 0, 0, 0, nan, 0, nan, nan, nan, 0, 0, 0, 0, 0, 0, 7298, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, nan, 4650, 0, 0, 6514, 0, 0, 0, 0, 0, 0, 0, nan, nan, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, nan, 0, 914, 0, 0, 7298, 0, 0, 0, 25236, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, nan, nan, 1797, 0, 0, 0, 0, 0, 0, 0, 3471, 0, 0, 0, 15024, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, 14344, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 3887, nan, 15024, 1055, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 3325, 0, 2202, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, 2829, 0, nan, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, nan, 7298, 0, 0, nan, 0, 7688, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, nan, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 4101, nan, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, nan, 0, nan, 0, 0, 0, 0, nan, 4064, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 2907, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 2174, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 2829, 0, nan, nan, 0, nan, 0, 0, nan, 0, 0, 0, 0, 7688, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, 7688, 0, 0, 0, 0, 0, 0, 0, nan, nan, 7688, 6418, 0, 0, 0, 0, 0, 0, 10520, 0, nan, nan, 0, 0, 0, 0, 0, 5178, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 2407, 0, 0, nan, 0, 0, nan, 0, 3273, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5013, 0, 3137, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 7298, 0, nan, 0, 0, nan, nan, 0, nan, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 99999, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 7688, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, nan, 15024, 0, 0, nan, 0, 0, 0, 0, 0, 0, 7688, nan, 0, 0, 0, 0, 0, 0, 0, 0, 7298, 0, nan, 0, 0, 0, nan, 0, 4650, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 25236, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10520, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, 2885, 0, 0, 0, 0, 0, 0, 9386, 0, 0, 0, 0, 0, 0, 0, 0, 594, 0, 0, 0, nan, 0, 0, 0, 0, 4064, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 3464, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 4416, 0, 0, 15024, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 2050, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 7298, 0, 0, 0, 0, 0, nan, nan, 0, nan, 0, nan, nan, 0, nan, 7298, 9386, nan, 0, 0, 99999, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, 1055, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 10520, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, nan, nan, 0, 0, 0, nan, 0, nan, 0, 0, 1506, 0, 0, 0, nan, 0, 4386, 14084, 0, nan, 0, nan, nan, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, nan, 15024, nan, 0, 0, 0, 0, nan, 0, nan, nan, nan, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 14344, 0, nan, 0, 0, 0, 0, 0, nan, nan, nan, 0, nan, 0, 0, 0, 0, nan, nan, nan, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 2354, nan, nan, 0, nan, 3103, 0, 0, 0, nan, 5178, nan, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, nan, 0, 7298, nan, 3103, 0, 0, 0, 0, nan, 0, 0, nan, nan, 2407, 0, nan, nan, 0, 0, 3103, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, nan, nan, 0, 0, 5178, 0, 7298, nan, nan, 4650, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 4064, 3325, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, 10605, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 2414, 0, nan, 0, 10566, nan, 0, 0, nan, 0, 3942, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, nan, nan, 0, nan, nan, 0, 0, 0, nan, 0, 0]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df[:] = flat_data.reshape(df.shape)\n",
      "/home/tung/development/AutoCleanse/AutoCleanse/utils.py:99: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0, 0, 0, 0, 0, 0, 0, 0, 2205, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, nan, 0, 1977, 0, 0, 0, 0, 1485, 0, 0, 1902, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, nan, nan, 0, 0, nan, nan, nan, 0, nan, 1902, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2206, nan, 0, 0, 0, 0, 0, 0, 0, 1887, 1719, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, nan, 0, 1902, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 1721, 0, 0, 0, 0, 0, 0, 0, 1648, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, nan, 1977, 0, 0, 0, 0, nan, 1762, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, nan, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1628, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 1887, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, nan, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 1668, 0, 0, nan, nan, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, 1590, 0, nan, 0, 0, nan, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, nan, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1740, 0, nan, nan, 0, 0, nan, nan, 0, 0, nan, 0, nan, 0, 0, 0, 1902, nan, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 1741, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1977, 0, nan, nan, 0, nan, nan, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1628, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 1977, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, nan, nan, 0, 1902, nan, nan, 0, 0, 0, 0, nan, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, nan, 0, nan, 0, nan, 0, 0, 1485, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, nan, 0, 1977, 2042, 0, 0, nan, 0, 0, 0, 0, nan, nan, nan, nan, nan, 0, nan, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, 1380, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, nan, nan, 0, nan, 0, 0, 0, 1762, nan, 0, 0, 0, 0, nan, nan, 0, 1977, nan, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 1902, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 2258, 880, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1980, nan, 0, nan, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2051, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 1887, 0, nan, 0, 0, 0, 0, 1408, nan, 0, nan, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1672, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1977, 0, 0, 0, 0, 0, nan, 0, 0, nan, 1887, 0, 1726, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, nan, 1977, nan, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, nan, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 1092, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 1721, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, nan, nan, 0, 0, 0, nan, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1602, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, nan, nan, 0, 0, 0, nan, 0, nan, 0, 0, nan, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, 2415, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, nan, 0, nan, nan, 0, 0, nan, nan, nan, 0, 0, nan, nan, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, nan, 0, 0, nan, 0, 2415, 0, 0, 0, 0, 0, 0, 2415, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, nan, nan, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, 2002, 0, 0, nan, 0, nan, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, 2174, nan, 0, 0, nan, 0, 0, 0, 0, 1902, 0, nan, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1887, 0, 0, 0, 0, 0, nan, nan, 0, nan, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, nan, 0, 0, 0, nan, 0, 0, 0, nan, nan, 1876, nan, 1887, nan, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, nan, 0, 1408, 0, nan, nan, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 1668, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 1980, 0, 0, 0, 0, 0, nan, 1672, 0, 0, 0, 0, 0, nan, 0, nan, 0, nan, 0, 0, 0, nan, nan, 0, 1579, 0, 0, 0, 0, 0, 0, 0, 0, 1485, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, nan, nan, 0, nan, 0, 0, 0, 0, nan, 0, 1504, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, nan, nan, 0, 0, 0, nan, nan, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 2258, 0, 0, nan, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 1564, 0, nan, 0, 0, nan, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 1848, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, 213, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 2179, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 1721, 0, 0, nan, nan, nan, nan, 0, nan, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, 1902, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, 1977, 0, nan, 0, nan, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, nan, 0, 0, 0, nan, 0, nan, 0, nan, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, nan, 0, nan, 0, 0, 0, nan, 0, 0, 0, nan, nan, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, nan, 0, 0, nan, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 1887, 1887, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, nan, 0, nan, 0, 0, 0, nan, 0, nan, 0, nan, 0, 0, 0, nan, nan, 0, 0, 1672, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, nan, nan, 1485, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, 880, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 1602, nan, 0, 0, nan, 0, 0, 0, nan, 0, 0, nan, 0, nan, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2489, nan, 0, nan, 0, nan, 0, 0, 0, 0, nan, 0, 1590, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 2238, 0, nan, 0, 0, nan, 0, nan, 0, nan, 0, nan, 0, nan, 0, 0, 0, nan, 0, 0, nan, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, nan, 0, 0, 0, 0, nan, 0, nan, nan, 0, 1902, nan, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, nan, 0, nan, nan, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, nan, 2001, 0, 0, 0, 0, nan, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, nan, 1573, nan, 0, 0, nan, nan, nan, 0, 0, 0, 0, 0, 0, 1594, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 1485, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 1977, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, nan, 0, nan, nan, 0, 0, nan, 0, 0, 0, nan, nan, 0, 0, nan, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, 1977, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 1740, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, nan, 0, nan, 0, 0, 0, 0, nan, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2339, 0, 0, 0, 0, nan, 0, nan, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, nan, nan, 0, nan, 0, nan, 0, 0, 0, 0, nan, 0, 0, nan, nan, 0, 0, 0, 0, nan, 0, 0, nan, nan, 0, 0, nan, 0, nan, 0, 1740, 0, 0, nan, nan, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, nan, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, nan, 1902, 0, 0, 0, 0, 0, 0, 0, nan, nan, nan, 0, nan, 0, nan, 0, 0, nan, nan, 0, 0, 1485, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1485, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 1848, 0, 0, 2042, nan, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 1138, 0, nan, nan, 1579, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, nan, 0, 1258, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 1740, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 1651, 0, 0, 2002, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 1902, nan, nan, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, nan, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 1977, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, nan, 0, nan, 0, nan, 0, 0, 0, nan, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 2258, nan, nan, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, 1887, 0, nan, 0, 0, 0, 0, 0, 0, 1902, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, nan, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 1876, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, nan, 1887, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, nan, nan, 0, 0, 0, 1876, 0, nan, 0, nan, nan, nan, 0, 0, 0, nan, nan, 0, 1564, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, nan, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 1590, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, nan, nan, 0, 0, 0, 0, nan, 0, nan, nan, 0, 0, nan, nan, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 1902, 0, 0, nan, 0, 0, 0, 0, nan, 0, nan, 0, nan, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 2547, 0, 0, nan, 0, 0, 0, nan, 0, 0, nan, 0, nan, 2415, nan, nan, 0, 1977, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, 1741, 0, 0, 0, nan, 0, nan, nan, 0, nan, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, nan, nan, 0, 0, 2377, 1902, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 1902, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 2377, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, nan, nan, 0, nan, 0, nan, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, nan, nan, nan, 0, 0, 0, 0, 0, 0, 0, 1876, nan, 0, 0, 0, nan, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, 1741, 0, 0, nan, nan, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 1876, 0, 0, 0, 0, 0, 0, nan, 0, nan, nan, 0, 0, 0, 0, nan, 0, nan, 0, nan, 0, 0, 0, nan, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 2415, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, nan, nan, 0, nan, 0, 0, nan, 0, 0, 1564, 0, 0, 0, nan, nan, 0, 0, 0, nan, nan, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, nan, 2057, 0, 0, 0, 1485, 0, 0, nan, 0, 0, nan, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1977, nan, 0, 0, 0, 0, 0, 0, 0, 0, 1902, nan, 0, 0, 0, 0, 2559, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 1977, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, nan, nan, 0, nan, 0, 0, 0, 0, 0, nan, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, nan, 0, nan, nan, 0, 0, 0, nan, nan, 0, 0, 0, 0, nan, nan, nan, 0, 0, 0, 1579, 0, 0, 1719, nan, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 1876, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, nan, 1902, 0, nan, 0, 0, nan, nan, 2080, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, nan, 0, 1980, 1719, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, nan, 0, 2002, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, 1740, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, nan, nan, 0, nan, 0, 0, nan, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, nan, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, nan, nan, 0, 0, 0, nan, 0, nan, 0, nan, nan, nan, 0, 0, nan, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 1902, nan, 0, nan, 2559, 0, nan, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 1669, nan, 1504, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1504, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, nan, 0, 2051, 0, nan, 0, nan, 0, nan, 0, 0, 0, nan, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, nan, 2051, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1902, nan, 0, 0, 1573, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, nan, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, 1980, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, 0, 0, nan, 1980, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2001, 0, 2377, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, nan, 0, 0, nan, 0, 0, 2001, nan, 0, 0, nan, 0, 0, 0, 0, 0, 0, 653, 1741, 0, 0, nan, 0, 0, 0, nan, 0, 0, 0, 0, nan, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 0, nan, nan, nan, 0, 0]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df[:] = flat_data.reshape(df.shape)\n",
      "/home/tung/development/AutoCleanse/AutoCleanse/utils.py:99: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[nan, 40, 40, 20, 84, 70, 40, nan, nan, 50, 40, nan, 40, nan, nan, nan, nan, nan, 30, nan, 40, nan, 40, 40, 48, 10, 40, 40, 40, nan, 40, 40, 50, nan, 48, 40, 60, 27, 50, 40, 40, 40, 40, nan, 9, 37, 55, 40, nan, 40, 22, 40, 40, 40, 40, 50, 40, 40, 45, nan, 50, 40, 35, 40, 35, nan, 18, 46, 28, 32, nan, nan, 40, nan, 80, 40, 40, nan, 40, 40, 50, 40, 50, 40, nan, 60, nan, 15, 30, 60, nan, 40, 40, 40, nan, 32, 24, 45, nan, 35, 20, nan, 40, 40, 40, 65, 10, 50, 25, 14, 24, 40, 40, 64, nan, 40, 40, 40, 40, 40, 40, 40, nan, nan, 43, 45, 40, nan, 50, 40, 60, 40, 40, 45, 55, 40, 50, 40, 45, nan, nan, 96, 40, 40, 75, 30, 40, 16, nan, nan, nan, nan, 32, 40, 40, 50, 40, 45, 53, 40, 18, nan, nan, 45, 45, 52, 40, 60, 40, 20, 40, 40, 38, 40, nan, nan, 40, 40, 40, nan, nan, nan, 40, 40, 48, 40, 40, 40, 40, 7, 40, 40, 30, 45, 4, 50, 40, 40, nan, 40, 40, 50, nan, 60, 40, 45, 60, 20, 70, nan, 30, 30, 28, 50, 40, 50, 30, 72, 40, nan, 10, 56, 40, 20, nan, 25, 45, 40, nan, 40, 16, 40, 40, 40, 40, 45, 50, nan, 20, 40, 35, 55, 30, 21, 35, nan, 35, 45, 40, nan, 40, 40, 55, 24, 40, 65, 40, 40, 20, 30, 65, 40, 30, 12, 40, 50, 25, 40, 5, 50, 40, 40, 15, 40, 40, 24, 40, 60, 40, 38, 60, 25, 40, 35, 35, 55, 50, nan, 70, nan, 39, 18, 40, 48, 40, 70, 40, 40, 40, 40, 48, 60, 50, 40, 45, 40, 40, nan, 40, nan, 20, 40, nan, 40, nan, 50, 40, 60, 30, 50, 80, 56, 50, nan, 45, nan, 50, 60, 40, 50, 32, 25, 30, 8, nan, 40, 45, 40, 99, 20, 40, 30, 35, 20, 54, 60, 48, 40, nan, 40, 25, 50, nan, 40, 20, 12, 41, nan, 20, 40, 40, 40, 35, 50, 40, nan, 40, 40, nan, 40, 20, 40, 55, 48, 55, nan, nan, 40, nan, 40, 40, 36, 50, 50, 42, 40, 50, nan, nan, 40, 20, 40, 40, 42, 55, 50, nan, 40, 40, 40, 40, 40, 25, 40, 45, 40, 40, 45, 48, 40, 40, 40, nan, nan, 60, 40, 45, 40, nan, 20, 55, 40, 50, 40, 40, 75, 40, 20, nan, 40, 40, 30, 15, 40, 40, 40, nan, 40, 50, nan, 40, 40, 40, nan, 62, 40, 30, nan, 70, nan, nan, 40, 35, 35, 50, 25, 40, nan, 10, 40, 40, 40, nan, 40, nan, nan, 42, nan, 38, 10, 40, 40, 40, 40, nan, nan, 40, 14, 40, 44, 40, 30, 4, 40, 40, 40, nan, 75, nan, nan, 15, 32, nan, nan, 44, 30, 36, nan, nan, nan, 20, 40, 40, 40, nan, 40, 84, 30, 40, 30, 40, 60, nan, 40, 40, 60, nan, 40, 40, 20, 40, 40, 36, 40, 40, 38, 40, 32, 32, 40, 50, 40, nan, nan, 40, 40, 20, nan, 40, 40, nan, 48, 30, nan, 40, 37, 40, 40, nan, 40, 40, nan, nan, 60, 20, 40, 40, 40, nan, 40, nan, 30, 45, 40, 40, 40, 65, 53, 40, nan, nan, nan, 24, 40, 37, nan, 40, 30, nan, 55, 40, 44, 40, 50, 40, 40, 40, 45, 45, 50, 24, nan, 40, 40, nan, 55, 40, 40, 48, 40, 48, 20, 25, 40, 15, 50, 54, 49, 45, 50, 40, nan, 50, 40, 30, 40, 40, 40, 40, 40, 40, 68, 40, 40, 40, 64, 40, 40, 15, 50, nan, 2, 40, 40, 40, 60, 40, 50, 50, 40, 40, 40, nan, nan, 40, 40, 40, 20, nan, 60, nan, 40, nan, 45, nan, 50, 32, 42, 50, 40, 40, 40, 40, 40, 40, 70, 40, nan, 42, 80, 40, 40, nan, 51, 70, nan, 14, 50, 40, 40, 40, nan, nan, 40, 45, nan, 40, nan, 40, nan, 40, 50, 40, 40, 45, 50, 40, 60, 40, 50, 8, 30, 40, 45, 40, nan, 50, nan, 40, 40, nan, 50, 40, 36, 10, 41, nan, 40, 40, nan, 40, 30, 40, nan, 50, 37, 20, 40, nan, 40, 40, 50, nan, 60, 40, 35, 60, 62, nan, 8, 60, 40, 40, 50, 40, 40, 40, 50, nan, 40, 45, nan, 40, nan, nan, 20, 70, nan, 35, 40, 40, 40, 48, 40, nan, 32, 60, 40, nan, 40, 40, 45, 40, 50, 45, 14, nan, 40, 40, 40, 40, 45, 45, 45, 18, 40, 45, 30, 40, 18, 40, 15, 50, 50, 40, 40, 40, 15, 60, 44, 45, nan, nan, 38, 45, nan, 75, 40, nan, 40, 35, 40, 40, 40, 99, 50, nan, 50, 40, 40, 40, 40, 40, 40, 25, 60, nan, 40, 40, 40, 45, 48, nan, 40, 40, nan, 40, 30, 40, 40, 30, 20, nan, 40, 40, 40, 60, 1, 40, nan, 40, nan, 30, 70, 40, 50, 50, 50, 57, 5, 40, 30, nan, 40, 50, 20, nan, nan, 40, 48, 40, 48, 30, 40, 40, 40, 40, 40, 70, 10, 40, 12, 40, nan, nan, 40, 16, nan, 15, 40, 28, 40, 40, 30, 47, 14, 40, nan, 40, 35, 30, 40, nan, 4, nan, 40, 45, 50, 40, nan, 78, 45, nan, 50, 40, 40, nan, 40, 40, 60, 50, 20, 65, 60, 55, 35, 40, 40, 84, nan, 30, 50, 40, 45, 60, 40, 46, 45, 16, 40, 40, 50, 50, 40, 55, 38, 39, 40, 40, 55, nan, 35, 48, 40, 75, 48, nan, 40, 40, nan, 40, 45, nan, 40, 40, 40, 6, nan, 40, 20, 40, nan, nan, nan, 40, 40, nan, 40, 75, 40, 45, nan, 60, nan, nan, 40, 30, 50, nan, 50, 99, 40, nan, nan, 40, 40, 35, 50, nan, 24, 40, 60, 50, 45, 40, nan, nan, 50, 40, 40, 40, 50, 40, 35, 40, 30, 60, 40, 40, 40, 40, 35, 65, 40, 40, 40, nan, 10, 40, 42, 50, 40, nan, nan, nan, nan, 40, 40, nan, nan, nan, 40, 24, 48, 44, 40, 40, 20, 40, nan, 30, nan, 60, 25, 46, nan, 18, nan, 90, 50, 65, nan, 40, 35, 40, 40, nan, 35, 5, 40, nan, nan, 20, 45, nan, 48, nan, nan, nan, 45, nan, 30, 40, 12, 50, nan, 40, 16, nan, 40, nan, nan, nan, 16, 35, 40, 40, 40, nan, 45, nan, nan, 50, nan, 40, 40, 50, nan, 60, 40, 50, 30, 60, nan, nan, nan, 40, 40, 40, 40, nan, 40, 40, nan, 32, 40, 40, 24, nan, 50, 40, 35, 40, 42, 40, nan, 45, 28, 38, nan, 8, 60, 40, 28, 60, 54, nan, 45, 30, 40, 40, nan, 40, 40, nan, 60, 40, 40, 25, 7, 40, 40, nan, 55, 60, 40, 50, 40, 20, 40, 40, 15, 45, nan, 40, nan, 40, 35, nan, nan, 36, 50, 40, 40, 40, 7, 40, 40, 38, 15, 40, 40, 40, 65, 75, 40, 30, 20, nan, 35, 50, 40, 40, 40, 20, nan, 55, nan, 42, 10, 40, nan, 40, 40, 40, 40, 50, nan, nan, nan, nan, 40, 20, 40, 60, 50, 25, 50, 40, 35, 60, 25, 48, nan, 12, 40, nan, 58, 50, 25, 40, 40, 40, 10, nan, 40, 60, 30, nan, 30, 20, 20, 20, 60, 50, 50, 52, nan, nan, 38, nan, nan, 40, nan, 43, 40, 45, 40, 40, 35, 40, 60, nan, 38, 40, 40, 30, 40, nan, 36, 40, 20, nan, 40, 40, 50, 55, nan, 40, 40, 35, nan, 40, nan, 50, 45, 15, 40, 50, 40, nan, 60, 40, 40, 40, 30, 32, 50, 40, 40, 40, nan, 36, 50, nan, 60, 14, 48, 80, 28, 5, 40, nan, nan, 45, 12, 40, 40, 50, 42, nan, nan, 15, 40, nan, 40, nan, 25, 45, nan, 40, 30, 40, 30, 60, 40, 60, nan, 32, nan, nan, nan, 12, 50, 40, 40, 40, 40, 57, 40, 60, 40, 50, nan, 45, 40, 40, 40, 40, 60, 40, nan, 40, nan, 40, 40, 40, 40, 35, 10, 38, 50, 55, nan, 40, 40, 40, nan, 40, 30, 40, nan, 50, 30, 40, 60, 40, 40, nan, nan, 40, 40, 38, 24, 40, 40, nan, nan, 40, 30, 15, 20, nan, nan, nan, 23, 12, 40, nan, 40, 40, 40, 60, 50, 40, nan, 40, nan, 45, 40, 45, nan, 30, nan, 40, 27, 65, nan, nan, 28, 30, 38, nan, nan, 15, 40, 45, 32, nan, nan, 40, 30, 45, nan, 50, 24, 50, 55, nan, 40, 40, 55, 55, 38, 45, 40, 45, 42, 72, 40, nan, nan, nan, 43, 20, 30, 40, 49, 72, 20, nan, 20, 45, 50, 40, 40, 20, 40, 24, 40, 37, nan, nan, nan, 44, 25, nan, 20, nan, 40, 10, 5, 32, 60, 40, 45, 40, 7, 40, 45, 40, nan, 40, 40, 40, 20, 44, 40, 70, 37, 60, nan, 35, 50, 40, 40, 20, 60, 45, 40, 18, 40, 60, 40, 45, 40, 40, 40, 25, 32, nan, 40, nan, 60, nan, nan, 45, 40, 40, 30, nan, 50, 40, 55, 45, 43, 48, 40, 5, 40, 40, 40, 35, 40, 40, nan, 26, nan, 40, nan, 20, nan, 30, nan, 40, nan, 20, 84, nan, 40, nan, 35, nan, 40, 15, 40, 25, 40, 40, 16, 70, 45, 40, nan, 48, 35, 39, 30, 40, 60, 40, 25, 40, 45, 40, nan, 40, 40, 50, 45, 45, 40, 20, 48, nan, nan, 40, nan, 38, 45, 48, 40, 40, 40, 40, 40, 40, 40, 40, 50, 50, 12, 45, 32, 40, 40, 50, 72, nan, 40, nan, 40, 40, nan, 40, 43, nan, 50, 50, 60, 40, 40, 20, 40, 60, nan, 45, 40, nan, 50, 24, 45, nan, 40, 40, 52, 40, 40, nan, 40, 40, 40, 24, 25, nan, 40, 40, nan, 40, 40, 48, 40, 52, 40, 40, 40, 40, 25, nan, 35, 40, nan, nan, 24, 40, nan, 40, 5, 40, 45, 48, 50, nan, 63, 66, 40, 40, 60, 30, 40, 60, 40, 50, nan, 40, 40, 55, 38, nan, 40, 40, 40, nan, 35, 40, nan, 40, 22, nan, 80, nan, 40, 12, 50, 40, 37, 60, 40, 45, 40, 40, nan, 40, 55, 60, 35, 40, 30, 55, 40, 40, nan, 30, nan, nan, nan, 40, nan, nan, 40, 40, 27, 20, 48, 40, 40, 40, 40, nan, nan, 40, 50, 40, 40, 50, 45, 42, 55, 40, 50, 40, 35, 40, 40, 40, 15, 40, 30, 50, 35, 40, nan, 40, 45, nan, nan, 45, 20, 65, 45, 20, nan, 50, 32, 36, 40, 29, 40, 40, 40, nan, 45, 45, 40, 20, 30, 25, 40, 40, 40, 50, nan, nan, 40, 40, 48, 36, 40, 50, 45, 40, 48, nan, 30, nan, 40, nan, 40, 40, 40, 40, 35, 50, 40, nan, 40, 50, 40, 40, 45, 40, 50, 20, 60, 16, 40, 24, nan, 20, nan, 38, 66, 35, nan, 40, 45, 15, 40, 45, nan, 40, 30, 40, nan, 40, 50, 55, 40, nan, 84, nan, 80, 40, nan, 40, 40, nan, 40, 48, 18, 20, 40, 20, 40, 8, nan, 20, 32, 50, 12, 60, 40, 65, nan, 35, 60, 16, 45, 60, 40, nan, 40, 30, 40, 8, 40, 50, 16, 35, 43, 40, 40, nan, 48, 40, nan, nan, 40, 40, 40, 30, 60, 60, 30, 60, 40, nan, 40, 10, 40, 25, 45, nan, 40, 50, 40, 40, 45, nan, nan, 50, 20, 40, nan, 60, 40, 15, nan, 35, 38, 40, 40, 35, 12, 60, nan, nan, 40, nan, 40, 40, 40, 8, 35, 38, 40, 45, 40, nan, 50, 48, 35, nan, 40, 25, nan, 32, 50, 60, 40, 45, nan, nan, 40, 30, 40, 40, 24, 75, 40, 50, 52, nan, 15, 30, 38, 47, nan, 60, 40, 20, 28, 40, 40, 55, 40, 40, nan, 40, 40, 50, 30, 40, 35, 40, 40, 50, 40, nan, 24, 50, nan, 30, 36, 6, 42, 40, 50, 28, 40, 50, nan, 40, 40, 50, 40, 40, 18, 8, 45, 45, 30, nan, 40, 40, 40, 35, 40, 40, 40, 35, 40, 30, 35, 25, 40, 50, 40, 40, nan, nan, 15, 38, 40, 40, 40, 25, 40, 30, 45, 20, 40, nan, 40, 44, 60, 20, 40, 40, 30, nan, nan, 50, 40, 40, nan, 45, 40, 40, nan, 24, 15, nan, 38, 40, 44, 40, 40, 10, nan, nan, 56, 48, 40, 60, 45, nan, 40, nan, 60, 40, 45, 60, 18, 50, nan, 40, 50, 32, 40, nan, 40, nan, 40, 50, 50, 40, 40, 66, nan, 40, nan, 20, 40, nan, 16, nan, 30, 40, nan, 40, 45, 45, nan, 70, 60, nan, nan, nan, 8, 60, 60, nan, 40, 40, 40, nan, 40, nan, nan, 48, 40, 40, 60, nan, 40, nan, 46, 32, 40, nan, 35, 40, 35, nan, 40, 40, nan, 36, nan, 40, 40, 40, 40, 55, 40, 20, 40, nan, 50, 40, 40, 40, 40, 40, 40, 55, 60, 40, 30, 57, 40, 40, nan, nan, 55, 40, 10, nan, 45, 46, 40, 50, 25, 40, 56, 10, 60, 40, 36, 50, 48, 38, 30, 40, 40, 45, 50, 40, 55, 40, 60, 15, 40, 35, 46, 61, 40, 65, 35, 35, 40, 40, 35, 40, nan, 72, 10, 40, 38, nan, 60, 40, 40, 40, nan, nan, 38, 40, 42, 24, 40, 40, 15, 40, 45, 50, 40, nan, 40, 40, 14, 45, 40, 30, 50, 40, 60, 4, nan, 55, 45, 40, 40, nan, nan, 40, 40, 40, nan, 40, 40, 40, 50, 40, 50, 45, 40, 46, 48, 40, nan, 40, nan, 60, 45, 40, 40, 45, 20, 20, 40, nan, 40, 40, 25, nan, 60, 35, nan, 52, nan, 40, 40, 25, 45, nan, 40, 38, 48, nan, 50, nan, nan, nan, 40, 40, 30, nan, 40, 40, 40, 40, 54, 42, nan, 35, 38, 20, 60, 65, 60, 40, 40, 15, nan, nan, nan, 25, nan, 55, 91, 40, nan, 35, nan, 40, 40, 85, 40, 16, 40, nan, 16, 20, 40, 40, nan, nan, 42, 45, 50, 60, 40, 60, 40, 40, 40, nan, nan, nan, 35, 38, nan, 40, 60, 50, 60, 40, 40, 40, nan, 40, nan, nan, nan, nan, 38, 43, 50, nan, 40, 38, 35, 42, 48, 40, 70, 40, 50, 40, 40, nan, 50, 40, 40, 40, nan, nan, 70, 50, 52, 40, 20, 40, nan, 70, 40, 40, 40, 40, 40, 40, nan, 54, 45, 50, 40, 40, 40, 16, 48, nan, 45, 50, 40, nan, nan, 40, 32, nan, nan, 40, 35, nan, nan, nan, 45, 35, nan, 3, 40, 50, 40, nan, 60, 50, 25, 45, nan, nan, 40, 40, 40, nan, 40, nan, 40, 35, 40, 40, 55, 39, 30, 45, 40, 40, nan, 40, nan, 60, 50, nan, nan, nan, 40, 40, 60, nan, 17, 65, nan, 10, 40, 40, 35, 40, 27, nan, 40, 60, nan, 10, 40, 38, 40, 20, 48, 30, 40, 50, 40, 40, 40, 50, nan, 40, 40, 38, nan, 40, nan, 40, 36, nan, nan, nan, 45, 20, 45, nan, 60, 40, 40, 24, 40, 30, 40, 40, nan, 50, 20, 35, 40, 30, 40, 30, 50, 80, 40, nan, 50, nan, 40, 40, 40, 60, 30, 17, nan, 40, 32, 40, 60, 35, nan, nan, 40, 40, nan, 50, 40, nan, 50, 30, 12, 40, 35, nan, 40, 65, 40, nan, 40, 40, nan, 40, nan, nan, 50, 40, 40, 45, 40, 15, 40, 40, nan, 40, 45, 40, 60, 50, 40, 30, 40, 45, 50, 40, 45, 40, nan, 40, 40, 50, 35, nan, 40, 20, 80, nan, 49, nan, 40, 56, 40, nan, nan, 38, 53, 40, 70, 40, 40, 40, nan, nan, 50, 40, 40, 50, 50, nan, 15, 40, 40, 48, 20, 32, 37, 40, 40, 40, nan, 35, 40, nan, 20, 20, 60, 40, 34, nan, 40, 40, nan, 15, 35, 25, 40, nan, 10, 30, 35, 45, 40, 38, 35, 25, 40, 60, 20, nan, nan, nan, 40, 10, nan, 40, 36, 19, 40, 40, 40, 50, 40, 40, 40, 40, 40, nan, 40, 40, 55, 40, nan, 38, 40, nan, nan, 40, 40, 50, nan, 80, 20, 35, nan, 40, nan, 35, nan, 40, 40, 50, nan, 40, nan, 30, 40, 40, 40, 55, 40, nan, 40, nan, 40, 48, 40, 40, 30, 18, 40, nan, 40, 38, 45, 20, 42, 55, 46, 40, 20, 39, 24, 42, 40, 55, 50, 48, nan, 30, 2, 35, nan, nan, 60, 20, nan, 60, 40, nan, nan, nan, 40, 40, 40, 8, nan, 50, 10, nan, 20, 40, 50, nan, 40, 40, 38, 40, 40, 40, 50, nan, 40, 20, nan, 25, 50, nan, 40, 40, 70, 52, 40, nan, 40, 31, 40, 35, nan, nan, 40, 20, 35, 40, 40, nan, 70, nan, 55, 40, nan, 26, 37, 40, 40, 50, nan, nan, 40, 12, 30, 40, 40, 40, 10, 20, nan, nan, 40, 40, 20, nan, nan, 50, 60, 40, nan, 40, nan, 40, 50, 40, 40, 24, 48, 40, nan, 40, 40, 40, 50, 65, 30, 40, 40, 40, 40, nan, nan, nan, 40, 56, 50, 40, 30, 5, 25, 20, 20, 40, 5, 40, 40, nan, 55, 40, 50, nan, 60, 40, 40, 28, 30, 35, 55, nan, 40, nan, 40, 21, 40, 16, 40, nan, 12, 40, 40, 99, 55, 35, nan, 40, 40, nan, 40, 50, 40, nan, 35, 50, nan, 40, 65, nan, 40, 40, nan, nan, 25, 50, 40, 70, 40, 55, 40, 40, 40, 50, nan, 40, 40, 20, 43, 60, 40, 20, 40, 16, 38, 40, 43, 40, nan, 40, nan, 50, 30, 40, nan, 60, 10, 43, 25, 40, 40, 60, 99, 40, 45, 25, 35, 40, 38, 40, 50, 40, 40, 80, 70, nan, 45, nan, 40, 55, 40, 40, nan, 40, nan, 40, nan, 30, nan, nan, 20, 4, nan, 40, nan, 40, 60, 40, 40, 40, nan, 40, 40, 40, 48, 35, 15, 20, nan, 40, 36, 35, 60, 40, nan, 48, nan, 40, nan, nan, nan, 40, 40, 50, 20, 72, 40, 20, 25, nan, 40, 25, 25, 40, 40, 40, nan, 25, 50, nan, 40, 40, 40, nan, 45, nan, 40, 40, 52, 40, nan, 36, 40, nan, 56, 70, nan, 40, 2, 22, 40, nan, nan, 35, 55, nan, 40, nan, nan, 45, 40, 60, 40, 40, 45, 50, 20, 55, nan, 40, 40, nan, 40, 40, 45, 50, 30, nan, 40, 40, 40, 40, 40, 40, 60, nan, 40, 40, 40, 40, 30, nan, nan, 20, 40, nan, 40, nan, nan, 40, 42, 55, 50, 40, 40, nan, 44, 40, 40, nan, 24, nan, 38, 16, nan, nan, 6, 4, 39, nan, nan, nan, 40, 25, nan, 15, nan, 40, nan, 40, 40, 40, nan, nan, 5, 40, nan, 45, 35, 40, 30, 45, nan, nan, 40, 56, 40, nan, 40, 38, 65, nan, 30, 55, nan, 40, 48, nan, 40, 40, 38, 40, 45, 40, 60, 40, 40, 26, 20, nan, 40, 50, 40, 60, 8, 10, 40, 65, 50, nan, nan, 45, 58, 40, 30, nan, 32, nan, nan, 43, nan, 7, 40, nan, 40, 50, 40, 30, 45, 40, 48, nan, 50, nan, 50, 28, 40, nan, 40, 40, 25, 10, 33, nan, 24, 35, nan, 60, nan, 40, 40, 35, nan, nan, 45, 30, 40, 44, 45, nan, nan, 40, nan, 37, 37, 40, 40, nan, 40, 44, 30, 40, 45, nan, nan, 35, nan, nan, nan, 40, 40, 35, 40, 40, 20, nan, nan, 40, 40, 40, 35, 40, 40, 40, 25, 35, nan, 40, 15, nan, 40, 40, 70, 40, nan, 12, 40, 32, 40, 45, nan, 40, 50, 84, 30, 40, 40, 40, 44, 38, 40, nan, 60, 20, nan, 60, 40, 40, 45, 35, nan, 40, 50, 40, nan, 30, 20, 35, 40, 60, nan, 60, 45, 40, 45, 40, 50, 40, nan, 40, nan, nan, nan, nan, 55, 99, 45, nan, 40, nan, 40, 50, nan, 55, nan, 45, 19, nan, 40, 40, 40, 40, 42, 40, 40, 40, 44, 36, 46, 34, 32, nan, 40, nan, 45, nan, 40, 50, nan, 40, 40, 36, 40, nan, 24, nan, 35, 50, 44, 40, 24, 40, 60, 38, 56, 40, 40, 50, 40, 40, 50, 85, nan, 40, 36, 40, 40, 40, 40, 40, nan, 45, 40, 47, 42, 52, 40, 15, 18, 65, 40, nan, 30, 50, 40, 37, nan, 40, 40, 40, 40, 40, 40, 40, 40, nan, nan, 40, 20, nan, nan, 40, 48, 38, 20, 40, nan, 50, 35, 50, 90, nan, 40, nan, 40, 8, 60, 70, nan, 30, nan, 50, 40, 55, 40, 45, 40, 40, 50, 50, 30, 40, 40, 40, 40, 40, 40, 24, 40, 32, nan, 50, nan, 6, 50, 50, 52, nan, nan, 40, 20, nan, 20, nan, 40, 40, 40, nan, nan, 40, 8, 40, 50, nan, 60, nan, 40, nan, 38, 26, nan, 40, 40, 40, 40, 50, 40, 8, 65, 40, 32, 36, 40, 35, 40, 40, 50, 40, 40, 40, 40, nan, 40, 39, nan, nan, 65, 30, 40, 45, 35, 40, 40, 40, 40, 40, 40, 64, 40, nan, 40, 50, 30, 40, 16, nan, nan, 40, 56, 60, 20, 60, 40, 40, 40, 60, 40, 48, 40, 60, 40, 50, 40, 9, nan, 40, 40, 50, 50, 48, nan, nan, 25, 35, 65, 40, 6, 50, 55, 40, 41, 40, 40, 40, 25, 40, 50, 40, 66, 40, nan, 20, 46, 40, 40, 56, 40, 40, 45, 40, 40, nan, 45, 45, 45, 40, 40, 58, nan, 40, 40, 35, 48, 30, 35, 40, 55, 40, 20, nan, 35, 40, 40, nan, nan, 40, 40, 40, 40, 40, 43, 65, 30, 25, 50, 50, 45, 30, 40, 40, 40, 35, 50, 25, 40, nan, 43, 50, nan, 40, 20, 40, 38, 70, 35, 40, 45, nan, 15, 20, 24, 40, 40, nan, 40, nan, 24, 50, nan, nan, 40, nan, 50, 40, 40, 50, nan, 50, 26, 40, 24, nan, 40, 20, 40, 40, 40, nan, 99, 55, 48, 40, 40, nan, nan, 8, nan, 40, nan, 20, 40, 25, 65, 50, 40, 40, 40, 60, 40, 38, nan, 45, 40, 20, 50, 38, nan, 40, 40, nan, 40, 40, nan, nan, 40, 21, 40, 40, nan, 48, 20, 40, 50, 50, 25, 50, 40, 40, 60, 50, 47, 50, 7, 35, 50, 30, 40, 25, 40, 40, nan, 40, 40, 30, 65, nan, 20, 40, nan, 38, nan, 50, 40, 35, nan, 40, nan, nan, 40, 60, 40, 20, nan, 40, nan, 25, 4, nan, 40, nan, 20, 40, nan, 40, 40, 64, 45, nan, 60, 40, nan, 45, 40, 27, 56, 40, 50, 40, 50, 60, 50, 40, 60, 48, 99, 40, 40, 40, nan, 15, 21, nan, 50, 43, 40, 50, 75, 20, 40, 23, 40, 70, nan, 20, 48, 20, 45, 50, 40, nan, 40, 7, 40, 35, 16, nan, nan, 40, 45, 40, 40, 44, 60, nan, 40, 40, nan, 40, 40, 40, 40, 55, nan, 30, 40, 40, 40, 45, 40, 70, 40, 32, 40, nan, 40, 30, 40, 40, 40, 12, nan, 25, 40, 40, 15, nan, 30, 40, 40, 40, nan, 40, 60, 45, 40, 40, 40, 20, nan, nan, nan, 35, 40, 42, nan, 35, 45, 40, nan, 40, 40, 40, nan, 25, 35, nan, 40, 40, 50, 40, nan, 40, 40, 38, 40, 40, 20, 40, 24, 60, 40, nan, nan, 38, nan, nan, 50, 36, 45, nan, 50, 40, 30, 50, nan, 30, 8, 40, 44, 40, 48, 40, nan, 40, 45, 40, 38, 30, 40, 54, nan, 40, 40, nan, 38, nan, 40, nan, 45, 40, nan, 40, 35, 40, 40, 55, 4, 20, 18, 32, 40, 40, nan, nan, 42, 25, 46, 30, nan, nan, nan, 40, 25, 40, 40, 40, 40, 20, 40, 80, 40, 50, nan, 40, 40, 40, 50, 40, nan, 40, nan, 40, 40, 45, 70, 40, 40, 40, 55, 36, 50, 60, nan, 40, 40, 80, 40, 40, 40, 35, 40, 45, 40, 40, 40, 50, 40, 87, 42, 45, 40, 40, 40, 50, nan, 40, 40, 50, nan, 40, nan, 30, 40, 40, 40, nan, 40, 45, 40, 55, 40, 45, 60, 99, 40, nan, nan, nan, nan, 20, 42, 40, nan, 60, 52, 35, 35, 35, nan, 35, 40, 25, 42, 40, nan, 40, 60, 40, 50, nan, 40, 60, 43, nan, 40, 35, 55, 50, 14, 40, 40, 35, 40, 8, 20, nan, nan, 40, 30, 40, 20, 10, 40, 30, 90, 40, nan, 16, 16, 55, nan, 45, nan, 25, 20, 45, nan, 40, 40, 40, 30, nan, 40, 50, 45, 55, nan, 50, 45, 20, 50, 25, 40, 8, nan, 60, 49, 40, 40, 40, 40, 40, 20, 40, 14, 20, 50, 55, nan, 40, 60, 30, 40, 60, nan, 60, 40, 28, 60, nan, 56, 38, 40, 50, 25, nan, 50, nan, nan, nan, 35, 37, 40, nan, 50, 30, 60, 72, 20, 25, 75, 36, 40, 50, 40, 50, nan, 55, 40, 40, 50, 40, 25, 44, 50, nan, 30, 40, nan, nan, 50, 40, 40, 60, 40, nan, 40, 50, 45, 40, 50, nan, 40, 40, 40, 40, nan, 45, 50, 50, 20, 40, 40, 40, 40, nan, nan, 40, 10, 55, 45, 25, 40, 40, 60, nan, 60, 25, 40, nan, 40, 32, 40, nan, 40, 40, 37, 40, 35, 55, 40, 25, 55, 40, 35, nan, nan, 40, 48, nan, 60, 40, nan, nan, 40, nan, nan, 50, nan, nan, 40, 40, 20, 50, 55, nan, 40, nan, 40, 40, 40, 60, nan, 40, 40, 30, nan, 40, 55, 40, 50, nan, nan, nan, 37, 40, 40, 10, 40, 40, nan, nan, 40, 40, 40, nan, 40, nan, 40, 35, 40, 25, 40, 30, nan, 50, nan, 50, 40, 40, nan, 48, 65, nan, 20, 40, 30, nan, nan, 16, 35, 45, 35, 40, nan, 45, nan, 40, 47, nan, 50, 48, 22, 30, 40, 40, 60, 40, 50, 15, 55, 50, 36, 15, 40, 50, 40, 25, 18, 55, 24, 38, 60, 40, 40, 47, nan, 40, 40, 40, 15, 35, 35, 7, 38, 18, 40, nan, nan, nan, 40, 40, 50, 30, 50, 32, 35, 40, 50, nan, 2, nan, 40, 32, nan, 40, 40, 40, 20, nan, nan, 40, nan, 45, nan, 20, 55, 40, nan, 20, nan, 40, 24, 40, nan, 40, nan, 38, nan, 40, nan, 40, 56, 45, 60, 50, nan, 40, nan, 40, 40, 40, 40, 40, 55, 40, 40, 40, nan, 35, 20, 40, 45, 38, 30, 40, 40, 40, 24, 40, 35, 45, 20, 36, nan, 30, 40, 40, nan, 50, 36, 35, 55, 40, 40, 20, 14, nan, nan, 45, 38, 47, 25, 5, 40, 20, 40, 40, 40, 50, 40, 60, 25, nan, 40, 50, 40, 45, nan, 40, 40, 50, 45, 40, 24, 48, 60, 40, 50, 20, nan, 32, 40, 30, 30, 40, 40, 60, 40, 40, 40, nan, 55, 40, 40, 20, nan, nan, 40, 40, nan, 40, 40, 30, 45, 40, 40, 40, 30, 40, nan, 40, nan, 33, nan, 40, 40, 40, 40, 40, 30, 55, 38, 40, 40, 43, 40, 35, 40, 40, 40, 20, 46, 40, 54, 40, 8, 40, 40, 50, 60, 32, 15, 40, nan, nan, 45, 40, 22, 45, 40, 15, 40, 40, 60, 50, 40, 40, 50, nan, nan, 50, 40, 25, 40, 40, nan, 40, 40, 40, 30, 50, 40, 50, 40, 20, 50, 55, 40, 16, nan, 30, 60, 40, 40, 40, 40, 20, 25, 35, 40, 11, 40, 40, 40, 40, 40, 30, 20, nan, 40, 40, nan, 50, 40, 40, 20, 45, 45, 37, 50, 50, 40, 40, 40, 50, nan, 40, 24, 72, 44, 55, 40, 20, nan, 40, nan, nan, 25, 40, 40, 40, 56, 40, 40, nan, 44, 40, 40, 40, 40, 30, 40, nan, 40, nan, 40, 30, nan, 40, nan, 40, nan, 45, 35, 38, 46, 50, nan, nan, 40, nan, 40, nan, 40, 35, 60, nan, nan, 40, 40, nan, 40, 50, 40, 20, 60, 45, 40, 35, 40, nan, 40, 40, nan, nan, 78, 40, 70, 44, 98, 55, 40, 35, 25, 40, 46, 40, 40, 60, 40, 40, 30, 15, 44, 50, 30, nan, 39, 40, 40, 30, 40, 45, 32, nan, nan, 40, nan, 55, 48, 35, 60, nan, 40, 40, nan, 40, 40, 40, 40, nan, 40, 40, 45, 40, nan, nan, 40, 35, 20, 20, nan, 40, 50, 6, 25, 60, 10, 70, 38, 30, 55, 20, 35, 15, nan, nan, 40, 6, 50, 27, 40, 60, nan, 45, nan, 30, 40, 40, 40, nan, 51, 40, 60, 8, nan, 40, 40, 20, 20, 40, 12, 40, 5, nan, 28, 20, 30, 40, nan, 40, nan, 40, 42, 40, 40, 40, 50, nan, 24, nan, 48, 50, 40, 40, 40, 50, 36, 40, 60, 60, 48, 36, 40, nan, 12, 30, 45, 40, 70, nan, nan, 35, 40, nan, 40, 48]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df[:] = flat_data.reshape(df.shape)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "onehotencoder = OneHotEncoder(handle_unknown='ignore',sparse_output=False)\n",
    "preprocessor = Preprocessor(scaler,onehotencoder)\n",
    "\n",
    "X_train,X_val,X_test = preprocessor.split(df=df,\n",
    "                                        train_ratio=0.7,\n",
    "                                        val_ratio=0.15,\n",
    "                                        test_ratio=0.15,\n",
    "                                        random_seed=42)\n",
    "X_dirty = replace_with_nan(X_test,0.2,42)\n",
    "\n",
    "X_train = preprocessor.fit_transform(input_df=X_train,\n",
    "                                    continous_columns=continous_columns,\n",
    "                                    categorical_columns=categorical_columns)\n",
    "\n",
    "X_val = preprocessor.transform(input_df=X_val,    \n",
    "                               continous_columns=continous_columns,\n",
    "                               categorical_columns=categorical_columns)                          \n",
    "\n",
    "X_test = preprocessor.transform(input_df=X_test,   \n",
    "                                continous_columns=continous_columns,\n",
    "                                categorical_columns=categorical_columns)  \n",
    "\n",
    "X_dirty = preprocessor.transform(input_df=X_dirty,   \n",
    "                                continous_columns=continous_columns,\n",
    "                                categorical_columns=categorical_columns)\n",
    "categories = preprocessor.encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education.num</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>workclass_?</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Never-worked</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>...</th>\n",
       "      <th>native.country_Portugal</th>\n",
       "      <th>native.country_Puerto-Rico</th>\n",
       "      <th>native.country_Scotland</th>\n",
       "      <th>native.country_South</th>\n",
       "      <th>native.country_Taiwan</th>\n",
       "      <th>native.country_Thailand</th>\n",
       "      <th>native.country_Trinadad&amp;Tobago</th>\n",
       "      <th>native.country_United-States</th>\n",
       "      <th>native.country_Vietnam</th>\n",
       "      <th>native.country_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28296</th>\n",
       "      <td>0.424658</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9208.575629</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28217</th>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8054</th>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4223</th>\n",
       "      <td>-8742.361300</td>\n",
       "      <td>8561.805903</td>\n",
       "      <td>-5708.054784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.193878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22723</th>\n",
       "      <td>8448.118926</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>7859.623854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.846939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21656</th>\n",
       "      <td>0.109589</td>\n",
       "      <td>6693.105868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7976.678645</td>\n",
       "      <td>0.346939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28318</th>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2640.493095</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32547</th>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>-8312.431233</td>\n",
       "      <td>-4863.080020</td>\n",
       "      <td>-7774.083226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9375</th>\n",
       "      <td>0.342466</td>\n",
       "      <td>-7669.257613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9477</th>\n",
       "      <td>0.123288</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.479592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4885 rows  107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               age  education.num  capital.gain  capital.loss  hours.per.week  \\\n",
       "28296     0.424658       0.266667      0.000000      0.000000     9208.575629   \n",
       "28217     0.150685       0.533333      0.000000      0.000000        0.397959   \n",
       "8054      0.287671       0.266667      0.000000      0.000000        0.397959   \n",
       "4223  -8742.361300    8561.805903  -5708.054784      0.000000        0.193878   \n",
       "22723  8448.118926       0.666667   7859.623854      0.000000        0.846939   \n",
       "...            ...            ...           ...           ...             ...   \n",
       "21656     0.109589    6693.105868      0.000000   7976.678645        0.346939   \n",
       "28318     0.027397       0.400000      0.000000   2640.493095        0.397959   \n",
       "32547     0.301370       0.733333  -8312.431233  -4863.080020    -7774.083226   \n",
       "9375      0.342466   -7669.257613      0.000000      0.000000        0.397959   \n",
       "9477      0.123288       0.600000      0.000000      0.000000        0.479592   \n",
       "\n",
       "       workclass_?  workclass_Federal-gov  workclass_Local-gov  \\\n",
       "28296          1.0                    0.0                  0.0   \n",
       "28217          1.0                    0.0                  0.0   \n",
       "8054           0.0                    0.0                  0.0   \n",
       "4223           0.0                    0.0                  0.0   \n",
       "22723          0.0                    0.0                  0.0   \n",
       "...            ...                    ...                  ...   \n",
       "21656          0.0                    0.0                  0.0   \n",
       "28318          0.0                    0.0                  0.0   \n",
       "32547          0.0                    0.0                  1.0   \n",
       "9375           0.0                    0.0                  0.0   \n",
       "9477           0.0                    0.0                  0.0   \n",
       "\n",
       "       workclass_Never-worked  workclass_Private  ...  \\\n",
       "28296                     0.0                0.0  ...   \n",
       "28217                     0.0                0.0  ...   \n",
       "8054                      0.0                0.0  ...   \n",
       "4223                      0.0                0.0  ...   \n",
       "22723                     0.0                1.0  ...   \n",
       "...                       ...                ...  ...   \n",
       "21656                     0.0                0.0  ...   \n",
       "28318                     0.0                0.0  ...   \n",
       "32547                     0.0                0.0  ...   \n",
       "9375                      0.0                1.0  ...   \n",
       "9477                      0.0                0.0  ...   \n",
       "\n",
       "       native.country_Portugal  native.country_Puerto-Rico  \\\n",
       "28296                      0.0                         0.0   \n",
       "28217                      0.0                         0.0   \n",
       "8054                       0.0                         0.0   \n",
       "4223                       0.0                         0.0   \n",
       "22723                      0.0                         0.0   \n",
       "...                        ...                         ...   \n",
       "21656                      0.0                         0.0   \n",
       "28318                      0.0                         0.0   \n",
       "32547                      0.0                         0.0   \n",
       "9375                       0.0                         0.0   \n",
       "9477                       0.0                         0.0   \n",
       "\n",
       "       native.country_Scotland  native.country_South  native.country_Taiwan  \\\n",
       "28296                      0.0                   0.0                    0.0   \n",
       "28217                      0.0                   0.0                    0.0   \n",
       "8054                       0.0                   0.0                    0.0   \n",
       "4223                       0.0                   0.0                    0.0   \n",
       "22723                      0.0                   0.0                    0.0   \n",
       "...                        ...                   ...                    ...   \n",
       "21656                      0.0                   0.0                    0.0   \n",
       "28318                      0.0                   0.0                    0.0   \n",
       "32547                      0.0                   0.0                    0.0   \n",
       "9375                       0.0                   0.0                    0.0   \n",
       "9477                       0.0                   0.0                    0.0   \n",
       "\n",
       "       native.country_Thailand  native.country_Trinadad&Tobago  \\\n",
       "28296                      0.0                             0.0   \n",
       "28217                      0.0                             0.0   \n",
       "8054                       0.0                             0.0   \n",
       "4223                       0.0                             0.0   \n",
       "22723                      0.0                             0.0   \n",
       "...                        ...                             ...   \n",
       "21656                      0.0                             0.0   \n",
       "28318                      0.0                             0.0   \n",
       "32547                      0.0                             0.0   \n",
       "9375                       0.0                             0.0   \n",
       "9477                       0.0                             0.0   \n",
       "\n",
       "       native.country_United-States  native.country_Vietnam  \\\n",
       "28296                           1.0                     0.0   \n",
       "28217                           1.0                     0.0   \n",
       "8054                            1.0                     0.0   \n",
       "4223                            1.0                     0.0   \n",
       "22723                           1.0                     0.0   \n",
       "...                             ...                     ...   \n",
       "21656                           1.0                     0.0   \n",
       "28318                           1.0                     0.0   \n",
       "32547                           1.0                     0.0   \n",
       "9375                            1.0                     0.0   \n",
       "9477                            1.0                     0.0   \n",
       "\n",
       "       native.country_Yugoslavia  \n",
       "28296                        0.0  \n",
       "28217                        0.0  \n",
       "8054                         0.0  \n",
       "4223                         0.0  \n",
       "22723                        0.0  \n",
       "...                          ...  \n",
       "21656                        0.0  \n",
       "28318                        0.0  \n",
       "32547                        0.0  \n",
       "9375                         0.0  \n",
       "9477                         0.0  \n",
       "\n",
       "[4885 rows x 107 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dirty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) Check save/load function of preprocessor\n",
    "\n",
    "Both functiona take in 2 parameters:\n",
    "\n",
    "    - Suffix of the preprocessor name, in the example below would be **preprocessor_main.pkl**\n",
    "    - Save/load location: can either be \"local\" to save/load in the home folder or \"bucketfs\" to save/load to/from Exasol BucketFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "preprocessor.save(\"main\",\"local\")\n",
    "preprocessor.save(\"main\",\"bucketfs\")\n",
    "preprocessor = Preprocessor(scaler=MinMaxScaler(),encoder=OneHotEncoder(sparse=False))\n",
    "preprocessor2.load(\"main\",\"local\")\n",
    "preprocessor2.load(\"main\",\"bucketfs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert dataframes into datasets, and create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PlainDataset(X_train)\n",
    "val_dataset = PlainDataset(X_val)\n",
    "test_dataset = PlainDataset(X_test)\n",
    "dirty_dataset = PlainDataset(X_dirty)\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    tensor_data = torch.stack([item[0] for item in batch])\n",
    "    indices = [item[1] for item in batch]\n",
    "    return tensor_data, indices\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True,collate_fn=custom_collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True, collate_fn=custom_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True, collate_fn=custom_collate_fn)\n",
    "dirty_loader = DataLoader(dirty_dataset, batch_size=batch_size, shuffle=False, drop_last=True, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [X_train.shape[1],1024,128]   \n",
    "wlc = (1,1) \n",
    "\n",
    "autoencoder = Autoencoder(layers=layers,dropout_enc=[(0,0.0)],dropout_dec=[(0,0.1)], batch_norm=True, \\\n",
    "                          learning_rate=1e-4,weight_decay=1e-5,l1_strength=1e-5,l2_strength=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(autoencoder.to(device),torch.tensor(X_train.values).float().to(device).shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) Model can be loaded from checkpoint after instantiation\n",
    "\n",
    "The function takes in 2 parameters:\n",
    "\n",
    "    - Suffix of the preprocessor name, in the example below would be **autoencoder_main.pkl**\n",
    "    - Save/load location: can either be \"local\" to load in the home folder or \"bucketfs\" to load from Exasol BucketFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "autoencoder.load(\"local\",\"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Training Progress: 100%|| 356/356 [00:12<00:00, 27.52it/s]\n",
      "Epoch [1/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Training Loss: 6.51186028\n",
      "Epoch [1/100], Validation Loss: 2.39420251\n",
      "Epoch [1/100], Training CE Loss: 6.45458449\n",
      "Epoch [1/100], Validation CE Loss: 2.35875442\n",
      "Epoch [1/100], Training MSE Loss: 0.05727580\n",
      "Epoch [1/100], Validation MSE Loss: 0.03544809\n",
      "Epoch [1/100], Training Loss Comp: 6.51186028\n",
      "Epoch [1/100], Validation Loss Comp: 2.39420251\n",
      "Epoch [1/100]: Learning Rate = [0.0001]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Training Progress: 100%|| 356/356 [00:12<00:00, 29.19it/s]\n",
      "Epoch [2/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Training Loss: 1.45376648\n",
      "Epoch [2/100], Validation Loss: 0.82513203\n",
      "Epoch [2/100], Training CE Loss: 1.42414442\n",
      "Epoch [2/100], Validation CE Loss: 0.79886463\n",
      "Epoch [2/100], Training MSE Loss: 0.02962206\n",
      "Epoch [2/100], Validation MSE Loss: 0.02626741\n",
      "Epoch [2/100], Training Loss Comp: 1.45376648\n",
      "Epoch [2/100], Validation Loss Comp: 0.82513203\n",
      "Epoch [2/100]: Learning Rate = [0.0001]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/100], Training Progress: 100%|| 356/356 [00:12<00:00, 28.79it/s]\n",
      "Epoch [3/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100], Training Loss: 0.59678315\n",
      "Epoch [3/100], Validation Loss: 0.42467861\n",
      "Epoch [3/100], Training CE Loss: 0.57300065\n",
      "Epoch [3/100], Validation CE Loss: 0.40312602\n",
      "Epoch [3/100], Training MSE Loss: 0.02378251\n",
      "Epoch [3/100], Validation MSE Loss: 0.02155259\n",
      "Epoch [3/100], Training Loss Comp: 0.59678315\n",
      "Epoch [3/100], Validation Loss Comp: 0.42467861\n",
      "Epoch [3/100]: Learning Rate = [0.0001]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/100], Training Progress: 100%|| 356/356 [00:12<00:00, 28.16it/s]\n",
      "Epoch [4/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100], Training Loss: 0.33864608\n",
      "Epoch [4/100], Validation Loss: 0.28084032\n",
      "Epoch [4/100], Training CE Loss: 0.31748882\n",
      "Epoch [4/100], Validation CE Loss: 0.26084352\n",
      "Epoch [4/100], Training MSE Loss: 0.02115727\n",
      "Epoch [4/100], Validation MSE Loss: 0.01999680\n",
      "Epoch [4/100], Training Loss Comp: 0.33864608\n",
      "Epoch [4/100], Validation Loss Comp: 0.28084032\n",
      "Epoch [4/100]: Learning Rate = [0.0001]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Training Progress: 100%|| 356/356 [00:12<00:00, 28.56it/s]\n",
      "Epoch [5/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Training Loss: 0.22021056\n",
      "Epoch [5/100], Validation Loss: 0.19374763\n",
      "Epoch [5/100], Training CE Loss: 0.20061890\n",
      "Epoch [5/100], Validation CE Loss: 0.17607940\n",
      "Epoch [5/100], Training MSE Loss: 0.01959166\n",
      "Epoch [5/100], Validation MSE Loss: 0.01766823\n",
      "Epoch [5/100], Training Loss Comp: 0.22021056\n",
      "Epoch [5/100], Validation Loss Comp: 0.19374763\n",
      "Epoch [5/100]: Learning Rate = [0.0001]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/100], Training Progress: 100%|| 356/356 [00:12<00:00, 29.27it/s]\n",
      "Epoch [6/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100], Training Loss: 0.15196413\n",
      "Epoch [6/100], Validation Loss: 0.15003542\n",
      "Epoch [6/100], Training CE Loss: 0.13465823\n",
      "Epoch [6/100], Validation CE Loss: 0.13400740\n",
      "Epoch [6/100], Training MSE Loss: 0.01730590\n",
      "Epoch [6/100], Validation MSE Loss: 0.01602802\n",
      "Epoch [6/100], Training Loss Comp: 0.15196413\n",
      "Epoch [6/100], Validation Loss Comp: 0.15003542\n",
      "Epoch [6/100]: Learning Rate = [0.0001]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/100], Training Progress: 100%|| 356/356 [00:12<00:00, 28.31it/s]\n",
      "Epoch [7/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100], Training Loss: 0.10914267\n",
      "Epoch [7/100], Validation Loss: 0.11550182\n",
      "Epoch [7/100], Training CE Loss: 0.09356863\n",
      "Epoch [7/100], Validation CE Loss: 0.10133796\n",
      "Epoch [7/100], Training MSE Loss: 0.01557405\n",
      "Epoch [7/100], Validation MSE Loss: 0.01416386\n",
      "Epoch [7/100], Training Loss Comp: 0.10914267\n",
      "Epoch [7/100], Validation Loss Comp: 0.11550182\n",
      "Epoch [7/100]: Learning Rate = [0.0001]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/100], Training Progress: 100%|| 356/356 [00:12<00:00, 28.09it/s]\n",
      "Epoch [8/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100], Training Loss: 0.08835858\n",
      "Epoch [8/100], Validation Loss: 0.10208140\n",
      "Epoch [8/100], Training CE Loss: 0.07452423\n",
      "Epoch [8/100], Validation CE Loss: 0.08889668\n",
      "Epoch [8/100], Training MSE Loss: 0.01383435\n",
      "Epoch [8/100], Validation MSE Loss: 0.01318472\n",
      "Epoch [8/100], Training Loss Comp: 0.08835858\n",
      "Epoch [8/100], Validation Loss Comp: 0.10208140\n",
      "Epoch [8/100]: Learning Rate = [0.0001]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/100], Training Progress: 100%|| 356/356 [00:12<00:00, 28.04it/s]\n",
      "Epoch [9/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 33.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100], Training Loss: 0.06836925\n",
      "Epoch [9/100], Validation Loss: 0.08567826\n",
      "Epoch [9/100], Training CE Loss: 0.05580785\n",
      "Epoch [9/100], Validation CE Loss: 0.07424589\n",
      "Epoch [9/100], Training MSE Loss: 0.01256140\n",
      "Epoch [9/100], Validation MSE Loss: 0.01143238\n",
      "Epoch [9/100], Training Loss Comp: 0.06836925\n",
      "Epoch [9/100], Validation Loss Comp: 0.08567826\n",
      "Epoch [9/100]: Learning Rate = [0.0001]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Training Progress: 100%|| 356/356 [00:12<00:00, 28.58it/s]\n",
      "Epoch [10/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Training Loss: 0.05703658\n",
      "Epoch [10/100], Validation Loss: 0.07253984\n",
      "Epoch [10/100], Training CE Loss: 0.04537811\n",
      "Epoch [10/100], Validation CE Loss: 0.06060506\n",
      "Epoch [10/100], Training MSE Loss: 0.01165847\n",
      "Epoch [10/100], Validation MSE Loss: 0.01193478\n",
      "Epoch [10/100], Training Loss Comp: 0.05703658\n",
      "Epoch [10/100], Validation Loss Comp: 0.07253984\n",
      "Epoch [10/100]: Learning Rate = [0.0001]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/100], Training Progress: 100%|| 356/356 [00:12<00:00, 28.33it/s]\n",
      "Epoch [11/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100], Training Loss: 0.04634275\n",
      "Epoch [11/100], Validation Loss: 0.06297465\n",
      "Epoch [11/100], Training CE Loss: 0.03570571\n",
      "Epoch [11/100], Validation CE Loss: 0.05231687\n",
      "Epoch [11/100], Training MSE Loss: 0.01063704\n",
      "Epoch [11/100], Validation MSE Loss: 0.01065778\n",
      "Epoch [11/100], Training Loss Comp: 0.04634275\n",
      "Epoch [11/100], Validation Loss Comp: 0.06297465\n",
      "Epoch [11/100]: Learning Rate = [0.0001]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [12/100], Training Progress: 100%|| 356/356 [00:12<00:00, 28.62it/s]\n",
      "Epoch [12/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100], Training Loss: 0.04106173\n",
      "Epoch [12/100], Validation Loss: 0.06479886\n",
      "Epoch [12/100], Training CE Loss: 0.03099527\n",
      "Epoch [12/100], Validation CE Loss: 0.05361445\n",
      "Epoch [12/100], Training MSE Loss: 0.01006645\n",
      "Epoch [12/100], Validation MSE Loss: 0.01118441\n",
      "Epoch [12/100], Training Loss Comp: 0.04106173\n",
      "Epoch [12/100], Validation Loss Comp: 0.06479886\n",
      "Epoch [12/100]: Learning Rate = [0.0001]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/100], Training Progress: 100%|| 356/356 [00:12<00:00, 28.79it/s]\n",
      "Epoch [13/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100], Training Loss: 0.03456916\n",
      "Epoch [13/100], Validation Loss: 0.05757061\n",
      "Epoch [13/100], Training CE Loss: 0.02542724\n",
      "Epoch [13/100], Validation CE Loss: 0.04873719\n",
      "Epoch [13/100], Training MSE Loss: 0.00914192\n",
      "Epoch [13/100], Validation MSE Loss: 0.00883342\n",
      "Epoch [13/100], Training Loss Comp: 0.03456916\n",
      "Epoch [13/100], Validation Loss Comp: 0.05757061\n",
      "Epoch [13/100]: Learning Rate = [0.0001]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [14/100], Training Progress: 100%|| 356/356 [00:12<00:00, 28.14it/s]\n",
      "Epoch [14/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100], Training Loss: 0.02968450\n",
      "Epoch [14/100], Validation Loss: 0.05862348\n",
      "Epoch [14/100], Training CE Loss: 0.02104773\n",
      "Epoch [14/100], Validation CE Loss: 0.04803162\n",
      "Epoch [14/100], Training MSE Loss: 0.00863677\n",
      "Epoch [14/100], Validation MSE Loss: 0.01059186\n",
      "Epoch [14/100], Training Loss Comp: 0.02968450\n",
      "Epoch [14/100], Validation Loss Comp: 0.05862348\n",
      "Epoch [14/100]: Learning Rate = [0.0001]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15/100], Training Progress: 100%|| 356/356 [00:12<00:00, 28.17it/s]\n",
      "Epoch [15/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100], Training Loss: 0.02699108\n",
      "Epoch [15/100], Validation Loss: 0.04722519\n",
      "Epoch [15/100], Training CE Loss: 0.01862856\n",
      "Epoch [15/100], Validation CE Loss: 0.03978225\n",
      "Epoch [15/100], Training MSE Loss: 0.00836252\n",
      "Epoch [15/100], Validation MSE Loss: 0.00744295\n",
      "Epoch [15/100], Training Loss Comp: 0.02699108\n",
      "Epoch [15/100], Validation Loss Comp: 0.04722519\n",
      "Epoch [15/100]: Learning Rate = [0.0001]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [16/100], Training Progress: 100%|| 356/356 [00:12<00:00, 28.06it/s]\n",
      "Epoch [16/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100], Training Loss: 0.02308985\n",
      "Epoch [16/100], Validation Loss: 0.04392504\n",
      "Epoch [16/100], Training CE Loss: 0.01520982\n",
      "Epoch [16/100], Validation CE Loss: 0.03630269\n",
      "Epoch [16/100], Training MSE Loss: 0.00788003\n",
      "Epoch [16/100], Validation MSE Loss: 0.00762235\n",
      "Epoch [16/100], Training Loss Comp: 0.02308985\n",
      "Epoch [16/100], Validation Loss Comp: 0.04392504\n",
      "Epoch [16/100]: Learning Rate = [0.0001]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [17/100], Training Progress: 100%|| 356/356 [00:12<00:00, 28.54it/s]\n",
      "Epoch [17/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100], Training Loss: 0.02087991\n",
      "Epoch [17/100], Validation Loss: 0.03931887\n",
      "Epoch [17/100], Training CE Loss: 0.01380626\n",
      "Epoch [17/100], Validation CE Loss: 0.03235434\n",
      "Epoch [17/100], Training MSE Loss: 0.00707364\n",
      "Epoch [17/100], Validation MSE Loss: 0.00696452\n",
      "Epoch [17/100], Training Loss Comp: 0.02087991\n",
      "Epoch [17/100], Validation Loss Comp: 0.03931887\n",
      "Epoch [17/100]: Learning Rate = [0.0001]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [18/100], Training Progress: 100%|| 356/356 [00:12<00:00, 29.25it/s]\n",
      "Epoch [18/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100], Training Loss: 0.02030895\n",
      "Epoch [18/100], Validation Loss: 0.04270734\n",
      "Epoch [18/100], Training CE Loss: 0.01349674\n",
      "Epoch [18/100], Validation CE Loss: 0.03603987\n",
      "Epoch [18/100], Training MSE Loss: 0.00681221\n",
      "Epoch [18/100], Validation MSE Loss: 0.00666747\n",
      "Epoch [18/100], Training Loss Comp: 0.02030895\n",
      "Epoch [18/100], Validation Loss Comp: 0.04270734\n",
      "Epoch [18/100]: Learning Rate = [0.0001]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [19/100], Training Progress: 100%|| 356/356 [00:12<00:00, 29.36it/s]\n",
      "Epoch [19/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100], Training Loss: 0.01682806\n",
      "Epoch [19/100], Validation Loss: 0.04041971\n",
      "Epoch [19/100], Training CE Loss: 0.01015232\n",
      "Epoch [19/100], Validation CE Loss: 0.03418896\n",
      "Epoch [19/100], Training MSE Loss: 0.00667574\n",
      "Epoch [19/100], Validation MSE Loss: 0.00623075\n",
      "Epoch [19/100], Training Loss Comp: 0.01682806\n",
      "Epoch [19/100], Validation Loss Comp: 0.04041971\n",
      "Epoch [19/100]: Learning Rate = [0.0001]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [20/100], Training Progress: 100%|| 356/356 [00:12<00:00, 29.18it/s]\n",
      "Epoch [20/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100], Training Loss: 0.01669444\n",
      "Epoch [20/100], Validation Loss: 0.03747796\n",
      "Epoch [20/100], Training CE Loss: 0.01052652\n",
      "Epoch [20/100], Validation CE Loss: 0.03215593\n",
      "Epoch [20/100], Training MSE Loss: 0.00616792\n",
      "Epoch [20/100], Validation MSE Loss: 0.00532203\n",
      "Epoch [20/100], Training Loss Comp: 0.01669444\n",
      "Epoch [20/100], Validation Loss Comp: 0.03747796\n",
      "Epoch [20/100]: Learning Rate = [0.0001]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [21/100], Training Progress: 100%|| 356/356 [00:12<00:00, 29.18it/s]\n",
      "Epoch [21/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100], Training Loss: 0.01682536\n",
      "Epoch [21/100], Validation Loss: 0.03579171\n",
      "Epoch [21/100], Training CE Loss: 0.01057488\n",
      "Epoch [21/100], Validation CE Loss: 0.02967925\n",
      "Epoch [21/100], Training MSE Loss: 0.00625048\n",
      "Epoch [21/100], Validation MSE Loss: 0.00611245\n",
      "Epoch [21/100], Training Loss Comp: 0.01682536\n",
      "Epoch [21/100], Validation Loss Comp: 0.03579171\n",
      "Epoch [21/100]: Learning Rate = [0.0001]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [22/100], Training Progress: 100%|| 356/356 [00:12<00:00, 29.14it/s]\n",
      "Epoch [22/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/100], Training Loss: 0.01532509\n",
      "Epoch [22/100], Validation Loss: 0.03400279\n",
      "Epoch [22/100], Training CE Loss: 0.00903459\n",
      "Epoch [22/100], Validation CE Loss: 0.02925990\n",
      "Epoch [22/100], Training MSE Loss: 0.00629050\n",
      "Epoch [22/100], Validation MSE Loss: 0.00474290\n",
      "Epoch [22/100], Training Loss Comp: 0.01532509\n",
      "Epoch [22/100], Validation Loss Comp: 0.03400279\n",
      "Epoch [22/100]: Learning Rate = [0.0001]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [23/100], Training Progress: 100%|| 356/356 [00:12<00:00, 29.10it/s]\n",
      "Epoch [23/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100], Training Loss: 0.01546754\n",
      "Epoch [23/100], Validation Loss: 0.03139852\n",
      "Epoch [23/100], Training CE Loss: 0.00965815\n",
      "Epoch [23/100], Validation CE Loss: 0.02671535\n",
      "Epoch [23/100], Training MSE Loss: 0.00580939\n",
      "Epoch [23/100], Validation MSE Loss: 0.00468317\n",
      "Epoch [23/100], Training Loss Comp: 0.01546754\n",
      "Epoch [23/100], Validation Loss Comp: 0.03139852\n",
      "Epoch [23/100]: Learning Rate = [0.0001]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [24/100], Training Progress: 100%|| 356/356 [00:12<00:00, 29.03it/s]\n",
      "Epoch [24/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/100], Training Loss: 0.01239031\n",
      "Epoch [24/100], Validation Loss: 0.03121456\n",
      "Epoch [24/100], Training CE Loss: 0.00692263\n",
      "Epoch [24/100], Validation CE Loss: 0.02645106\n",
      "Epoch [24/100], Training MSE Loss: 0.00546768\n",
      "Epoch [24/100], Validation MSE Loss: 0.00476350\n",
      "Epoch [24/100], Training Loss Comp: 0.01239031\n",
      "Epoch [24/100], Validation Loss Comp: 0.03121456\n",
      "Epoch [24/100]: Learning Rate = [0.0001]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [25/100], Training Progress: 100%|| 356/356 [00:12<00:00, 28.75it/s]\n",
      "Epoch [25/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 33.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/100], Training Loss: 0.01170858\n",
      "Epoch [25/100], Validation Loss: 0.03230876\n",
      "Epoch [25/100], Training CE Loss: 0.00637356\n",
      "Epoch [25/100], Validation CE Loss: 0.02582217\n",
      "Epoch [25/100], Training MSE Loss: 0.00533502\n",
      "Epoch [25/100], Validation MSE Loss: 0.00648659\n",
      "Epoch [25/100], Training Loss Comp: 0.01170858\n",
      "Epoch [25/100], Validation Loss Comp: 0.03230876\n",
      "Epoch [25/100]: Learning Rate = [1e-05]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [26/100], Training Progress: 100%|| 356/356 [00:12<00:00, 28.70it/s]\n",
      "Epoch [26/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/100], Training Loss: 0.00845616\n",
      "Epoch [26/100], Validation Loss: 0.02355344\n",
      "Epoch [26/100], Training CE Loss: 0.00468995\n",
      "Epoch [26/100], Validation CE Loss: 0.01973141\n",
      "Epoch [26/100], Training MSE Loss: 0.00376620\n",
      "Epoch [26/100], Validation MSE Loss: 0.00382203\n",
      "Epoch [26/100], Training Loss Comp: 0.00845616\n",
      "Epoch [26/100], Validation Loss Comp: 0.02355344\n",
      "Epoch [26/100]: Learning Rate = [1e-05]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [27/100], Training Progress: 100%|| 356/356 [00:12<00:00, 28.88it/s]\n",
      "Epoch [27/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/100], Training Loss: 0.00751059\n",
      "Epoch [27/100], Validation Loss: 0.02343598\n",
      "Epoch [27/100], Training CE Loss: 0.00386024\n",
      "Epoch [27/100], Validation CE Loss: 0.01971429\n",
      "Epoch [27/100], Training MSE Loss: 0.00365035\n",
      "Epoch [27/100], Validation MSE Loss: 0.00372169\n",
      "Epoch [27/100], Training Loss Comp: 0.00751059\n",
      "Epoch [27/100], Validation Loss Comp: 0.02343598\n",
      "Epoch [27/100]: Learning Rate = [1e-05]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [28/100], Training Progress: 100%|| 356/356 [00:12<00:00, 29.44it/s]\n",
      "Epoch [28/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/100], Training Loss: 0.00703663\n",
      "Epoch [28/100], Validation Loss: 0.02299380\n",
      "Epoch [28/100], Training CE Loss: 0.00343599\n",
      "Epoch [28/100], Validation CE Loss: 0.01907481\n",
      "Epoch [28/100], Training MSE Loss: 0.00360064\n",
      "Epoch [28/100], Validation MSE Loss: 0.00391899\n",
      "Epoch [28/100], Training Loss Comp: 0.00703663\n",
      "Epoch [28/100], Validation Loss Comp: 0.02299380\n",
      "Epoch [28/100]: Learning Rate = [1e-05]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [29/100], Training Progress: 100%|| 356/356 [00:12<00:00, 29.45it/s]\n",
      "Epoch [29/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/100], Training Loss: 0.00678914\n",
      "Epoch [29/100], Validation Loss: 0.02427184\n",
      "Epoch [29/100], Training CE Loss: 0.00324412\n",
      "Epoch [29/100], Validation CE Loss: 0.02056137\n",
      "Epoch [29/100], Training MSE Loss: 0.00354502\n",
      "Epoch [29/100], Validation MSE Loss: 0.00371047\n",
      "Epoch [29/100], Training Loss Comp: 0.00678914\n",
      "Epoch [29/100], Validation Loss Comp: 0.02427184\n",
      "Epoch [29/100]: Learning Rate = [1e-05]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [30/100], Training Progress: 100%|| 356/356 [00:12<00:00, 29.40it/s]\n",
      "Epoch [30/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/100], Training Loss: 0.00658389\n",
      "Epoch [30/100], Validation Loss: 0.02299354\n",
      "Epoch [30/100], Training CE Loss: 0.00298924\n",
      "Epoch [30/100], Validation CE Loss: 0.01947900\n",
      "Epoch [30/100], Training MSE Loss: 0.00359464\n",
      "Epoch [30/100], Validation MSE Loss: 0.00351454\n",
      "Epoch [30/100], Training Loss Comp: 0.00658389\n",
      "Epoch [30/100], Validation Loss Comp: 0.02299354\n",
      "Epoch [30/100]: Learning Rate = [1e-05]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [31/100], Training Progress: 100%|| 356/356 [00:12<00:00, 29.28it/s]\n",
      "Epoch [31/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/100], Training Loss: 0.00629875\n",
      "Epoch [31/100], Validation Loss: 0.02360979\n",
      "Epoch [31/100], Training CE Loss: 0.00284420\n",
      "Epoch [31/100], Validation CE Loss: 0.02003906\n",
      "Epoch [31/100], Training MSE Loss: 0.00345455\n",
      "Epoch [31/100], Validation MSE Loss: 0.00357073\n",
      "Epoch [31/100], Training Loss Comp: 0.00629875\n",
      "Epoch [31/100], Validation Loss Comp: 0.02360979\n",
      "Epoch [31/100]: Learning Rate = [1e-05]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [32/100], Training Progress: 100%|| 356/356 [00:12<00:00, 29.31it/s]\n",
      "Epoch [32/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/100], Training Loss: 0.00618052\n",
      "Epoch [32/100], Validation Loss: 0.02136516\n",
      "Epoch [32/100], Training CE Loss: 0.00274391\n",
      "Epoch [32/100], Validation CE Loss: 0.01777151\n",
      "Epoch [32/100], Training MSE Loss: 0.00343661\n",
      "Epoch [32/100], Validation MSE Loss: 0.00359365\n",
      "Epoch [32/100], Training Loss Comp: 0.00618052\n",
      "Epoch [32/100], Validation Loss Comp: 0.02136516\n",
      "Epoch [32/100]: Learning Rate = [1e-05]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [33/100], Training Progress: 100%|| 356/356 [00:12<00:00, 29.47it/s]\n",
      "Epoch [33/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/100], Training Loss: 0.00605166\n",
      "Epoch [33/100], Validation Loss: 0.02087578\n",
      "Epoch [33/100], Training CE Loss: 0.00265768\n",
      "Epoch [33/100], Validation CE Loss: 0.01742939\n",
      "Epoch [33/100], Training MSE Loss: 0.00339398\n",
      "Epoch [33/100], Validation MSE Loss: 0.00344639\n",
      "Epoch [33/100], Training Loss Comp: 0.00605166\n",
      "Epoch [33/100], Validation Loss Comp: 0.02087578\n",
      "Epoch [33/100]: Learning Rate = [1e-05]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [34/100], Training Progress: 100%|| 356/356 [00:11<00:00, 29.84it/s]\n",
      "Epoch [34/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 35.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/100], Training Loss: 0.00586187\n",
      "Epoch [34/100], Validation Loss: 0.02250771\n",
      "Epoch [34/100], Training CE Loss: 0.00257517\n",
      "Epoch [34/100], Validation CE Loss: 0.01902029\n",
      "Epoch [34/100], Training MSE Loss: 0.00328670\n",
      "Epoch [34/100], Validation MSE Loss: 0.00348742\n",
      "Epoch [34/100], Training Loss Comp: 0.00586187\n",
      "Epoch [34/100], Validation Loss Comp: 0.02250771\n",
      "Epoch [34/100]: Learning Rate = [1e-05]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [35/100], Training Progress: 100%|| 356/356 [00:11<00:00, 29.80it/s]\n",
      "Epoch [35/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/100], Training Loss: 0.00588076\n",
      "Epoch [35/100], Validation Loss: 0.02311647\n",
      "Epoch [35/100], Training CE Loss: 0.00259088\n",
      "Epoch [35/100], Validation CE Loss: 0.01958856\n",
      "Epoch [35/100], Training MSE Loss: 0.00328988\n",
      "Epoch [35/100], Validation MSE Loss: 0.00352790\n",
      "Epoch [35/100], Training Loss Comp: 0.00588076\n",
      "Epoch [35/100], Validation Loss Comp: 0.02311647\n",
      "Epoch [35/100]: Learning Rate = [1e-05]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [36/100], Training Progress: 100%|| 356/356 [00:12<00:00, 29.55it/s]\n",
      "Epoch [36/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/100], Training Loss: 0.00548157\n",
      "Epoch [36/100], Validation Loss: 0.02066910\n",
      "Epoch [36/100], Training CE Loss: 0.00226934\n",
      "Epoch [36/100], Validation CE Loss: 0.01745691\n",
      "Epoch [36/100], Training MSE Loss: 0.00321223\n",
      "Epoch [36/100], Validation MSE Loss: 0.00321218\n",
      "Epoch [36/100], Training Loss Comp: 0.00548157\n",
      "Epoch [36/100], Validation Loss Comp: 0.02066910\n",
      "Epoch [36/100]: Learning Rate = [1e-05]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [37/100], Training Progress: 100%|| 356/356 [00:12<00:00, 29.22it/s]\n",
      "Epoch [37/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 35.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/100], Training Loss: 0.00547319\n",
      "Epoch [37/100], Validation Loss: 0.02154450\n",
      "Epoch [37/100], Training CE Loss: 0.00230381\n",
      "Epoch [37/100], Validation CE Loss: 0.01833842\n",
      "Epoch [37/100], Training MSE Loss: 0.00316938\n",
      "Epoch [37/100], Validation MSE Loss: 0.00320608\n",
      "Epoch [37/100], Training Loss Comp: 0.00547319\n",
      "Epoch [37/100], Validation Loss Comp: 0.02154450\n",
      "Epoch [37/100]: Learning Rate = [1e-05]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [38/100], Training Progress: 100%|| 356/356 [00:12<00:00, 29.54it/s]\n",
      "Epoch [38/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/100], Training Loss: 0.00538070\n",
      "Epoch [38/100], Validation Loss: 0.02041744\n",
      "Epoch [38/100], Training CE Loss: 0.00224835\n",
      "Epoch [38/100], Validation CE Loss: 0.01727698\n",
      "Epoch [38/100], Training MSE Loss: 0.00313236\n",
      "Epoch [38/100], Validation MSE Loss: 0.00314045\n",
      "Epoch [38/100], Training Loss Comp: 0.00538070\n",
      "Epoch [38/100], Validation Loss Comp: 0.02041744\n",
      "Epoch [38/100]: Learning Rate = [1e-05]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [39/100], Training Progress: 100%|| 356/356 [00:12<00:00, 29.51it/s]\n",
      "Epoch [39/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/100], Training Loss: 0.00525946\n",
      "Epoch [39/100], Validation Loss: 0.02135465\n",
      "Epoch [39/100], Training CE Loss: 0.00222278\n",
      "Epoch [39/100], Validation CE Loss: 0.01807358\n",
      "Epoch [39/100], Training MSE Loss: 0.00303669\n",
      "Epoch [39/100], Validation MSE Loss: 0.00328107\n",
      "Epoch [39/100], Training Loss Comp: 0.00525946\n",
      "Epoch [39/100], Validation Loss Comp: 0.02135465\n",
      "Epoch [39/100]: Learning Rate = [1e-05]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [40/100], Training Progress: 100%|| 356/356 [00:12<00:00, 29.35it/s]\n",
      "Epoch [40/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/100], Training Loss: 0.00529379\n",
      "Epoch [40/100], Validation Loss: 0.01990076\n",
      "Epoch [40/100], Training CE Loss: 0.00223559\n",
      "Epoch [40/100], Validation CE Loss: 0.01672295\n",
      "Epoch [40/100], Training MSE Loss: 0.00305820\n",
      "Epoch [40/100], Validation MSE Loss: 0.00317781\n",
      "Epoch [40/100], Training Loss Comp: 0.00529379\n",
      "Epoch [40/100], Validation Loss Comp: 0.01990076\n",
      "Epoch [40/100]: Learning Rate = [1e-05]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [41/100], Training Progress: 100%|| 356/356 [00:12<00:00, 29.34it/s]\n",
      "Epoch [41/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/100], Training Loss: 0.00520121\n",
      "Epoch [41/100], Validation Loss: 0.02060406\n",
      "Epoch [41/100], Training CE Loss: 0.00218174\n",
      "Epoch [41/100], Validation CE Loss: 0.01760382\n",
      "Epoch [41/100], Training MSE Loss: 0.00301947\n",
      "Epoch [41/100], Validation MSE Loss: 0.00300024\n",
      "Epoch [41/100], Training Loss Comp: 0.00520121\n",
      "Epoch [41/100], Validation Loss Comp: 0.02060406\n",
      "Epoch [41/100]: Learning Rate = [1e-05]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [42/100], Training Progress: 100%|| 356/356 [00:12<00:00, 29.33it/s]\n",
      "Epoch [42/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/100], Training Loss: 0.00521056\n",
      "Epoch [42/100], Validation Loss: 0.01866597\n",
      "Epoch [42/100], Training CE Loss: 0.00222375\n",
      "Epoch [42/100], Validation CE Loss: 0.01559918\n",
      "Epoch [42/100], Training MSE Loss: 0.00298681\n",
      "Epoch [42/100], Validation MSE Loss: 0.00306679\n",
      "Epoch [42/100], Training Loss Comp: 0.00521056\n",
      "Epoch [42/100], Validation Loss Comp: 0.01866597\n",
      "Epoch [42/100]: Learning Rate = [1e-05]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [43/100], Training Progress: 100%|| 356/356 [00:12<00:00, 29.48it/s]\n",
      "Epoch [43/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/100], Training Loss: 0.00515581\n",
      "Epoch [43/100], Validation Loss: 0.01954335\n",
      "Epoch [43/100], Training CE Loss: 0.00222030\n",
      "Epoch [43/100], Validation CE Loss: 0.01643655\n",
      "Epoch [43/100], Training MSE Loss: 0.00293551\n",
      "Epoch [43/100], Validation MSE Loss: 0.00310680\n",
      "Epoch [43/100], Training Loss Comp: 0.00515581\n",
      "Epoch [43/100], Validation Loss Comp: 0.01954335\n",
      "Epoch [43/100]: Learning Rate = [1e-05]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [44/100], Training Progress: 100%|| 356/356 [00:12<00:00, 29.66it/s]\n",
      "Epoch [44/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/100], Training Loss: 0.00475024\n",
      "Epoch [44/100], Validation Loss: 0.02175461\n",
      "Epoch [44/100], Training CE Loss: 0.00183425\n",
      "Epoch [44/100], Validation CE Loss: 0.01877974\n",
      "Epoch [44/100], Training MSE Loss: 0.00291600\n",
      "Epoch [44/100], Validation MSE Loss: 0.00297487\n",
      "Epoch [44/100], Training Loss Comp: 0.00475024\n",
      "Epoch [44/100], Validation Loss Comp: 0.02175461\n",
      "Epoch [44/100]: Learning Rate = [1e-05]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [45/100], Training Progress: 100%|| 356/356 [00:12<00:00, 29.46it/s]\n",
      "Epoch [45/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/100], Training Loss: 0.00476901\n",
      "Epoch [45/100], Validation Loss: 0.02163702\n",
      "Epoch [45/100], Training CE Loss: 0.00196617\n",
      "Epoch [45/100], Validation CE Loss: 0.01855095\n",
      "Epoch [45/100], Training MSE Loss: 0.00280284\n",
      "Epoch [45/100], Validation MSE Loss: 0.00308607\n",
      "Epoch [45/100], Training Loss Comp: 0.00476901\n",
      "Epoch [45/100], Validation Loss Comp: 0.02163702\n",
      "Epoch [45/100]: Learning Rate = [1e-05]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [46/100], Training Progress: 100%|| 356/356 [00:12<00:00, 29.26it/s]\n",
      "Epoch [46/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/100], Training Loss: 0.00479369\n",
      "Epoch [46/100], Validation Loss: 0.01959338\n",
      "Epoch [46/100], Training CE Loss: 0.00198677\n",
      "Epoch [46/100], Validation CE Loss: 0.01665359\n",
      "Epoch [46/100], Training MSE Loss: 0.00280692\n",
      "Epoch [46/100], Validation MSE Loss: 0.00293980\n",
      "Epoch [46/100], Training Loss Comp: 0.00479369\n",
      "Epoch [46/100], Validation Loss Comp: 0.01959338\n",
      "Epoch [46/100]: Learning Rate = [1e-05]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [47/100], Training Progress: 100%|| 356/356 [00:12<00:00, 29.21it/s]\n",
      "Epoch [47/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/100], Training Loss: 0.00473729\n",
      "Epoch [47/100], Validation Loss: 0.01910952\n",
      "Epoch [47/100], Training CE Loss: 0.00188341\n",
      "Epoch [47/100], Validation CE Loss: 0.01616873\n",
      "Epoch [47/100], Training MSE Loss: 0.00285387\n",
      "Epoch [47/100], Validation MSE Loss: 0.00294080\n",
      "Epoch [47/100], Training Loss Comp: 0.00473729\n",
      "Epoch [47/100], Validation Loss Comp: 0.01910952\n",
      "Epoch [47/100]: Learning Rate = [1e-05]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [48/100], Training Progress: 100%|| 356/356 [00:12<00:00, 29.26it/s]\n",
      "Epoch [48/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/100], Training Loss: 0.00457257\n",
      "Epoch [48/100], Validation Loss: 0.01835696\n",
      "Epoch [48/100], Training CE Loss: 0.00177541\n",
      "Epoch [48/100], Validation CE Loss: 0.01555829\n",
      "Epoch [48/100], Training MSE Loss: 0.00279716\n",
      "Epoch [48/100], Validation MSE Loss: 0.00279867\n",
      "Epoch [48/100], Training Loss Comp: 0.00457257\n",
      "Epoch [48/100], Validation Loss Comp: 0.01835696\n",
      "Epoch [48/100]: Learning Rate = [1e-05]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [49/100], Training Progress: 100%|| 356/356 [00:12<00:00, 29.20it/s]\n",
      "Epoch [49/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/100], Training Loss: 0.00462070\n",
      "Epoch [49/100], Validation Loss: 0.01971735\n",
      "Epoch [49/100], Training CE Loss: 0.00183071\n",
      "Epoch [49/100], Validation CE Loss: 0.01708407\n",
      "Epoch [49/100], Training MSE Loss: 0.00278999\n",
      "Epoch [49/100], Validation MSE Loss: 0.00263328\n",
      "Epoch [49/100], Training Loss Comp: 0.00462070\n",
      "Epoch [49/100], Validation Loss Comp: 0.01971735\n",
      "Epoch [49/100]: Learning Rate = [1e-05]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [50/100], Training Progress: 100%|| 356/356 [00:12<00:00, 29.13it/s]\n",
      "Epoch [50/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/100], Training Loss: 0.00461912\n",
      "Epoch [50/100], Validation Loss: 0.01870091\n",
      "Epoch [50/100], Training CE Loss: 0.00186711\n",
      "Epoch [50/100], Validation CE Loss: 0.01601502\n",
      "Epoch [50/100], Training MSE Loss: 0.00275201\n",
      "Epoch [50/100], Validation MSE Loss: 0.00268588\n",
      "Epoch [50/100], Training Loss Comp: 0.00461912\n",
      "Epoch [50/100], Validation Loss Comp: 0.01870091\n",
      "Epoch [50/100]: Learning Rate = [1.0000000000000002e-06]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [51/100], Training Progress: 100%|| 356/356 [00:12<00:00, 29.15it/s]\n",
      "Epoch [51/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/100], Training Loss: 0.00432375\n",
      "Epoch [51/100], Validation Loss: 0.01843652\n",
      "Epoch [51/100], Training CE Loss: 0.00187900\n",
      "Epoch [51/100], Validation CE Loss: 0.01588091\n",
      "Epoch [51/100], Training MSE Loss: 0.00244475\n",
      "Epoch [51/100], Validation MSE Loss: 0.00255561\n",
      "Epoch [51/100], Training Loss Comp: 0.00432375\n",
      "Epoch [51/100], Validation Loss Comp: 0.01843652\n",
      "Epoch [51/100]: Learning Rate = [1.0000000000000002e-06]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [52/100], Training Progress: 100%|| 356/356 [00:12<00:00, 29.30it/s]\n",
      "Epoch [52/100], Validation Progress: 100%|| 76/76 [00:02<00:00, 34.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/100], Training Loss: 0.00423427\n",
      "Epoch [52/100], Validation Loss: 0.01956219\n",
      "Epoch [52/100], Training CE Loss: 0.00178316\n",
      "Epoch [52/100], Validation CE Loss: 0.01700943\n",
      "Epoch [52/100], Training MSE Loss: 0.00245111\n",
      "Epoch [52/100], Validation MSE Loss: 0.00255276\n",
      "Epoch [52/100], Training Loss Comp: 0.00423427\n",
      "Epoch [52/100], Validation Loss Comp: 0.01956219\n",
      "Epoch [52/100]: Learning Rate = [1.0000000000000002e-06]\n",
      "\n",
      "Early stopping triggered. Stopping training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "autoencoder.train_model(\n",
    "      patience=10,\n",
    "      num_epochs=100,\n",
    "      batch_size=batch_size,\n",
    "      train_loader=train_loader,\n",
    "      val_loader=val_loader,\n",
    "      continous_columns=continous_columns, \n",
    "      categorical_columns=categorical_columns, \n",
    "      categories=categories,\n",
    "      device=device,\n",
    "      wlc=wlc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) Model can be saved after training\n",
    "\n",
    "The function takes in 2 parameters:\n",
    "\n",
    "    - Suffix of the preprocessor name, in the example below would be **autoencoder_main.pkl**\n",
    "    - Save/load location: can either be \"local\" to load in the home folder or \"bucketfs\" to load from Exasol BucketFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved weight to autoencoder_main.pth\n"
     ]
    }
   ],
   "source": [
    "autoencoder.save(\"local\",\"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use trained model to clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clean progress: 100%|| 76/76 [00:04<00:00, 18.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MAE: 0.00116814\n",
      "\n",
      "MSE: 0.00012697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_data = autoencoder.clean(dirty_loader=dirty_loader,\n",
    "                                test_loader=test_loader,\n",
    "                                df=X_dirty,\n",
    "                                batch_size=batch_size,\n",
    "                                continous_columns=continous_columns, \n",
    "                                categorical_columns=categorical_columns, \n",
    "                                og_columns=og_columns,\n",
    "                                onehotencoder=preprocessor.encoder, \n",
    "                                scaler=preprocessor.scaler,\n",
    "                                device=device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         age  workclass         education      education.num  marital.status      occupation         relationship    race                sex       capital.gain    capital.loss    hours.per.week  native.country\n",
      "-----  -----  ----------------  -----------  ---------------  ------------------  -----------------  --------------  ------------------  ------  --------------  --------------  ----------------  ----------------\n",
      "28296     48  ?                 9th                        5  Separated           ?                  Not-in-family   Amer-Indian-Eskimo  Female               0               0                20  United-States\n",
      "28217     28  ?                 HS-grad                    9  Separated           ?                  Unmarried       White               Female               0               0                40  United-States\n",
      " 8054     38  Self-emp-not-inc  9th                        5  Divorced            Craft-repair       Not-in-family   White               Male                 0               0                40  United-States\n",
      " 4223     77  Self-emp-not-inc  HS-grad                    9  Never-married       Machine-op-inspct  Not-in-family   White               Male               401               0                20  United-States\n",
      "22723     33  Private           Assoc-voc                 11  Married-civ-spouse  Transport-moving   Husband         White               Male                 0               0                84  United-States\n"
     ]
    }
   ],
   "source": [
    "# original data\n",
    "print(tabulate(df.loc[[28296,28217,8054,4223,22723],og_columns],headers=og_columns,tablefmt=\"simple\",maxcolwidths=[None, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         age  workclass         education      education.num  marital.status      occupation         relationship    race                sex       capital.gain    capital.loss    hours.per.week  native.country\n",
      "-----  -----  ----------------  -----------  ---------------  ------------------  -----------------  --------------  ------------------  ------  --------------  --------------  ----------------  ----------------\n",
      "28296     48  ?                 9th                        6  Separated           ?                  Not-in-family   Amer-Indian-Eskimo  Female           -4947             230                30  United-States\n",
      "28217     31  ?                 HS-grad                    9  Separated           ?                  Unmarried       White               Female           -2421              -7                37  United-States\n",
      " 8054     36  Self-emp-not-inc  9th                        5  Divorced            Craft-repair       Not-in-family   White               Male              2361             127                39  United-States\n",
      " 4223     78  Self-emp-not-inc  HS-grad                    9  Never-married       Machine-op-inspct  Not-in-family   White               Male               124             125                25  United-States\n",
      "22723     35  Private           Assoc-voc                 11  Married-civ-spouse  Transport-moving   Husband         White               Male             -3132              32                80  United-States\n"
     ]
    }
   ],
   "source": [
    "# cleaned data\n",
    "print(tabulate(cleaned_data.loc[[28296,28217,8054,4223,22723]],headers=cleaned_data.columns.to_list(),tablefmt=\"simple\",maxcolwidths=[None, 4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use trained model to anonymize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anonymized_data = autoencoder.anonymize(df=X_test,\n",
    "                                        data_loader=test_loader,\n",
    "                                        batch_size=batch_size,\n",
    "                                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anonymized data\n",
    "print(tabulate(anonymized_data.round(decimals=4).iloc[:5,:32],headers=anonymized_data.columns.to_list(),tablefmt=\"simple\",maxcolwidths=[None, 6]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
