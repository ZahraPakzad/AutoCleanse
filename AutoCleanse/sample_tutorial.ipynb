{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import io\n",
    "import joblib\n",
    "import argparse\n",
    "\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "from tabulate import tabulate\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "from AutoCleanse.utils import *\n",
    "from AutoCleanse.dataloader import PlainDataset, DataLoader\n",
    "from AutoCleanse.autoencoder import *\n",
    "from AutoCleanse.loss_model import loss_CEMSE\n",
    "from AutoCleanse.preprocessor import Preprocessor\n",
    "from AutoCleanse.anonymize import anonymize\n",
    "from AutoCleanse.bucketfs_client import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Device configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9edd089ed0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup directory path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT_DIR = os.getcwd()\n",
    "os.chdir(PROJECT_DIR)\n",
    "DATASET_DIR = os.path.join(PROJECT_DIR,'dataset')\n",
    "EVAL_DIR = os.path.join(PROJECT_DIR,'evaluate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataframe and group features by their type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATASET_DIR,'adult.csv')).drop(columns=['fnlwgt','income'])\n",
    "continous_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_columns = df.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "og_columns = df.columns.to_list()\n",
    "df = df[continous_columns+categorical_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "onehotencoder = OneHotEncoder(sparse_output=False)\n",
    "preprocessor = Preprocessor(scaler,onehotencoder)\n",
    "\n",
    "X_train,X_val,X_test = preprocessor.split(df=df,\n",
    "                                        train_ratio=0.7,\n",
    "                                        val_ratio=0.15,\n",
    "                                        test_ratio=0.15,\n",
    "                                        random_seed=42)\n",
    "X_dirty = replace_with_nan(X_test,0,42)\n",
    "\n",
    "\n",
    "X_train = preprocessor.fit_transform(input_df=X_train,\n",
    "                                    continous_columns=continous_columns,\n",
    "                                    categorical_columns=categorical_columns)\n",
    "\n",
    "X_val = preprocessor.transform(input_df=X_val,    \n",
    "                               continous_columns=continous_columns,\n",
    "                               categorical_columns=categorical_columns)                          \n",
    "\n",
    "X_test = preprocessor.transform(input_df=X_test,   \n",
    "                                continous_columns=continous_columns,\n",
    "                                categorical_columns=categorical_columns)  \n",
    "\n",
    "X_dirty = preprocessor.transform(input_df=X_dirty,   \n",
    "                                continous_columns=continous_columns,\n",
    "                                categorical_columns=categorical_columns)\n",
    "\n",
    "categories = preprocessor.encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) Check save/load function of preprocessor\n",
    "\n",
    "Both functiona take in 2 parameters:\n",
    "\n",
    "    - Suffix of the preprocessor name, in the example below would be **preprocessor_main.pkl**\n",
    "    - Save/load location: can either be \"local\" to save/load in the home folder or \"bucketfs\" to save/load to/from Exasol BucketFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "preprocessor.save(\"main\",\"local\")\n",
    "preprocessor.save(\"main\",\"bucketfs\")\n",
    "preprocessor = Preprocessor(scaler=MinMaxScaler(),encoder=OneHotEncoder(sparse=False))\n",
    "preprocessor2.load(\"main\",\"local\")\n",
    "preprocessor2.load(\"main\",\"bucketfs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert dataframes into datasets, and create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PlainDataset(X_train)\n",
    "val_dataset = PlainDataset(X_val)\n",
    "test_dataset = PlainDataset(X_test)\n",
    "dirty_dataset = PlainDataset(X_dirty)\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    tensor_data = torch.stack([item[0] for item in batch])\n",
    "    indices = [item[1] for item in batch]\n",
    "    return tensor_data, indices\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True,collate_fn=custom_collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True, collate_fn=custom_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True, collate_fn=custom_collate_fn)\n",
    "dirty_loader = DataLoader(dirty_dataset, batch_size=batch_size, shuffle=False, drop_last=True, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [X_train.shape[1],1024,128]   \n",
    "wlc = (1,1) \n",
    "\n",
    "autoencoder = Autoencoder(layers=layers,dropout_enc=[(0,0.0)],dropout_dec=[(0,0.1)], batch_norm=True, \\\n",
    "                          learning_rate=1e-4,weight_decay=1e-5,l1_strength=1e-5,l2_strength=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                 [-1, 1024]         110,592\n",
      "       BatchNorm1d-2                 [-1, 1024]           2,048\n",
      "              ReLU-3                 [-1, 1024]               0\n",
      "           Dropout-4                 [-1, 1024]               0\n",
      "            Linear-5                  [-1, 128]         131,200\n",
      "       BatchNorm1d-6                  [-1, 128]             256\n",
      "              ReLU-7                  [-1, 128]               0\n",
      "            Linear-8                 [-1, 1024]         132,096\n",
      "              ReLU-9                 [-1, 1024]               0\n",
      "          Dropout-10                 [-1, 1024]               0\n",
      "           Linear-11                  [-1, 107]         109,675\n",
      "             ReLU-12                  [-1, 107]               0\n",
      "           Linear-13                  [-1, 107]          11,556\n",
      "================================================================\n",
      "Total params: 497,423\n",
      "Trainable params: 497,423\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 1.90\n",
      "Estimated Total Size (MB): 1.96\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(autoencoder.to(device),torch.tensor(X_train.values).float().to(device).shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) Model can be loaded from checkpoint after instantiation\n",
    "\n",
    "The function takes in 2 parameters:\n",
    "\n",
    "    - Suffix of the preprocessor name, in the example below would be **autoencoder_main.pkl**\n",
    "    - Save/load location: can either be \"local\" to load in the home folder or \"bucketfs\" to load from Exasol BucketFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "autoencoder.load(\"local\",\"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Training Progress: 100%|██████████| 356/356 [00:11<00:00, 29.83it/s]\n",
      "Epoch [1/1], Validation Progress: 100%|██████████| 76/76 [00:02<00:00, 35.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Training Loss: 6.47384357\n",
      "Epoch [1/1], Validation Loss: 2.32033534\n",
      "Epoch [1/1], Training CE Loss: 6.41617539\n",
      "Epoch [1/1], Validation CE Loss: 2.28548042\n",
      "Epoch [1/1], Training MSE Loss: 0.05766817\n",
      "Epoch [1/1], Validation MSE Loss: 0.03485493\n",
      "Epoch [1/1], Training Loss Comp: 6.47384357\n",
      "Epoch [1/1], Validation Loss Comp: 2.32033534\n",
      "Epoch [1/1]: Learning Rate = [0.0001]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "autoencoder.train_model(\n",
    "      patience=10,\n",
    "      num_epochs=100,\n",
    "      batch_size=batch_size,\n",
    "      train_loader=train_loader,\n",
    "      val_loader=val_loader,\n",
    "      continous_columns=continous_columns, \n",
    "      categorical_columns=categorical_columns, \n",
    "      categories=categories,\n",
    "      device=device,\n",
    "      wlc=wlc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) Model can be saved after training\n",
    "\n",
    "The function takes in 2 parameters:\n",
    "\n",
    "    - Suffix of the preprocessor name, in the example below would be **autoencoder_main.pkl**\n",
    "    - Save/load location: can either be \"local\" to load in the home folder or \"bucketfs\" to load from Exasol BucketFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "autoencoder.save(\"local\",\"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use trained model to clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clean progress: 100%|██████████| 76/76 [00:04<00:00, 17.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MAE: 0.01538386\n",
      "\n",
      "MSE: 0.01054435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_data = autoencoder.clean(dirty_loader=dirty_loader,\n",
    "                                test_loader=test_loader,\n",
    "                                df=X_dirty,\n",
    "                                batch_size=batch_size,\n",
    "                                continous_columns=continous_columns, \n",
    "                                categorical_columns=categorical_columns, \n",
    "                                og_columns=og_columns,\n",
    "                                onehotencoder=preprocessor.encoder, \n",
    "                                scaler=preprocessor.scaler,\n",
    "                                device=device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         age  workclass         education      education.num  marital.status      occupation         relationship    race                sex       capital.gain    capital.loss    hours.per.week  native.country\n",
      "-----  -----  ----------------  -----------  ---------------  ------------------  -----------------  --------------  ------------------  ------  --------------  --------------  ----------------  ----------------\n",
      "28296     48  ?                 9th                        5  Separated           ?                  Not-in-family   Amer-Indian-Eskimo  Female               0               0                20  United-States\n",
      "28217     28  ?                 HS-grad                    9  Separated           ?                  Unmarried       White               Female               0               0                40  United-States\n",
      " 8054     38  Self-emp-not-inc  9th                        5  Divorced            Craft-repair       Not-in-family   White               Male                 0               0                40  United-States\n",
      " 4223     77  Self-emp-not-inc  HS-grad                    9  Never-married       Machine-op-inspct  Not-in-family   White               Male               401               0                20  United-States\n",
      "22723     33  Private           Assoc-voc                 11  Married-civ-spouse  Transport-moving   Husband         White               Male                 0               0                84  United-States\n"
     ]
    }
   ],
   "source": [
    "# original data\n",
    "print(tabulate(df.loc[[28296,28217,8054,4223,22723],og_columns],headers=og_columns,tablefmt=\"simple\",maxcolwidths=[None, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         age  workclass         education       education.num  marital.status      occupation         relationship    race    sex       capital.gain    capital.loss    hours.per.week  native.country\n",
      "-----  -----  ----------------  ------------  ---------------  ------------------  -----------------  --------------  ------  ------  --------------  --------------  ----------------  ----------------\n",
      "28296     43  ?                 Some-college                6  Separated           ?                  Not-in-family   Black   Female           30033             306                 9  United-States\n",
      "28217     39  ?                 HS-grad                     5  Widowed             ?                  Unmarried       White   Female           41752            -431                14  United-States\n",
      " 8054     46  Self-emp-not-inc  Some-college                5  Divorced            Craft-repair       Not-in-family   White   Male              8891             268                47  United-States\n",
      " 4223     15  Self-emp-not-inc  HS-grad                     6  Never-married       Machine-op-inspct  Not-in-family   White   Male              -864             390                27  United-States\n",
      "22723     52  Private           Assoc-voc                  13  Married-civ-spouse  Transport-moving   Husband         White   Male             -7320            -154                55  United-States\n"
     ]
    }
   ],
   "source": [
    "# cleaned data\n",
    "print(tabulate(cleaned_data.loc[[28296,28217,8054,4223,22723]],headers=cleaned_data.columns.to_list(),tablefmt=\"simple\",maxcolwidths=[None, 4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use trained model to anonymize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Anonymize progress: 100%|██████████| 76/76 [00:02<00:00, 36.05it/s]\n"
     ]
    }
   ],
   "source": [
    "anonymized_data = autoencoder.anonymize(df=X_test,\n",
    "                                        data_loader=test_loader,\n",
    "                                        batch_size=batch_size,\n",
    "                                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0    1       2       3       4       5       6       7       8       9      10     11      12      13      14      15      16      17      18      19      20      21      22      23      24      25      26      27      28      29      30    31      32\n",
      "-----  ---  ------  ------  ------  ------  ------  ------  ------  ------  ------  -----  ------  ------  ------  ------  ------  ------  ------  ------  ------  ------  ------  ------  ------  ------  ------  ------  ------  ------  ------  ----  ------\n",
      "28296    0  0       0       0       0       0       2.1497  0       0       0       0      1.8243  0       0       0.0327  0       1.1492  1.0307  0       0       0       0       0       0       0       0       0       0       0       0          0  0\n",
      "28217    0  0       0.1836  0.1328  3.3679  0.0131  0.7436  0.9163  0       0       0      0       0.4534  0       2.226   0       0.4577  1.4482  0       0       0       0.6967  0       0.1591  0       0       0       0       0       0          0  0\n",
      " 8054    0  0       0       0.5764  0.8544  0       0       1.9503  1.4969  0       0      1.1713  0       0       0       1.8399  0.1464  0       2.3988  0.2801  2.1119  0       0       0       0.6088  0       1.2256  1.5853  0.5085  0          0  0\n",
      " 4223    0  1.1942  0       0       1.8025  0.4095  0       0.8201  0       0       0      1.0539  0       0.4053  0.0387  1.2978  0.7919  0.2075  0.4038  0       2.338   0       0.2547  2.2052  0.0243  0       0.0405  0.8857  1.6551  1.2359     0  3.4398\n",
      "22723    0  0       0.911   0.0998  0       1.3259  2.6544  0       0       2.5856  2.594  0       0       0       0       1.3453  0       0       0.5821  0       0       0.0448  0       0.0186  0       1.1756  1.821   1.6609  2.16    0          0  1.3516\n"
     ]
    }
   ],
   "source": [
    "# anonymized data\n",
    "print(tabulate(anonymized_data.round(decimals=4).iloc[:5,:32],headers=anonymized_data.columns.to_list(),tablefmt=\"simple\",maxcolwidths=[None, 6]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
